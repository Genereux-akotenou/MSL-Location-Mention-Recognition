{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010498,"end_time":"2024-09-04T08:56:30.760743","exception":false,"start_time":"2024-09-04T08:56:30.750245","status":"completed"},"tags":[]},"source":["<div style=\"padding: 0.5em; background-color: #1876d1; color: #fff; font-weight: bold; font-size: 1.4em;\">\n","    Fine-Tuning BERT for Location Mention Recognition\n","</div>\n","\n","This notebook demonstrates the process of fine-tuning a BERT model to recognize and categorize location mentions in text using the IDRISI dataset. The task at hand is a type of Named Entity Recognition (NER) where the goal is to identify and classify location names, such as countries, cities, or landmarks, within a given text.\n","\n","We utilize the BILOU (Begin, Inside, Last, Outside, Unit) labeling scheme, which provides detailed annotations of entity boundaries. Fine-tuning BERT with these structured labels allows the model to leverage its deep contextual understanding to perform highly accurate token classification, essential for detecting location mentions in diverse textual data.\n","\n","The notebook is structured as follows:\n","1. **Setup and Installation**: Install and import the necessary libraries.\n","2. **Data Ingestion and Preprocessing**: Load the IDRISI dataset and prepare it for modeling, including tokenization and label mapping.\n","3. **Modeling Preparation**: Create custom datasets, define label mappings, and set up the BERT model for token classification.\n","4. **Fine-Tuning**: Train the BERT model on the labeled data, optimizing for accuracy in location mention recognition.\n","5. **Evaluation**: Assess the performance of the fine-tuned model using the Word Error Rate Metric."]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009283,"end_time":"2024-09-04T08:56:30.780648","exception":false,"start_time":"2024-09-04T08:56:30.771365","status":"completed"},"tags":[]},"source":["### **Setup & Utils**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T04:20:58.982789Z","iopub.status.busy":"2024-09-06T04:20:58.982372Z","iopub.status.idle":"2024-09-06T04:21:43.702576Z","shell.execute_reply":"2024-09-06T04:21:43.701398Z","shell.execute_reply.started":"2024-09-06T04:20:58.982751Z"},"papermill":{"duration":29.226751,"end_time":"2024-09-04T08:57:00.016507","exception":false,"start_time":"2024-09-04T08:56:30.789756","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\n","Collecting transformers\n","  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jiwer\n","  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\n","Collecting werpy\n","  Downloading werpy-2.1.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.7)\n","Collecting wandb\n","  Downloading wandb-0.17.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.33.0)\n","Collecting accelerate\n","  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\n","Collecting rapidfuzz<4,>=3 (from jiwer)\n","  Downloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.13.0)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n","Downloading werpy-2.1.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wandb-0.17.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, jiwer, werpy, wandb, accelerate, transformers\n","  Attempting uninstall: wandb\n","    Found existing installation: wandb 0.17.7\n","    Uninstalling wandb-0.17.7:\n","      Successfully uninstalled wandb-0.17.7\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.33.0\n","    Uninstalling accelerate-0.33.0:\n","      Successfully uninstalled accelerate-0.33.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.0\n","    Uninstalling transformers-4.44.0:\n","      Successfully uninstalled transformers-4.44.0\n","Successfully installed accelerate-0.34.2 jiwer-3.0.4 rapidfuzz-3.9.7 transformers-4.44.2 wandb-0.17.9 werpy-2.1.2\n"]}],"source":["!pip install transformers jiwer werpy wandb pandas accelerate -U"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T04:21:43.705196Z","iopub.status.busy":"2024-09-06T04:21:43.704842Z","iopub.status.idle":"2024-09-06T04:22:00.419500Z","shell.execute_reply":"2024-09-06T04:22:00.418487Z","shell.execute_reply.started":"2024-09-06T04:21:43.705161Z"},"papermill":{"duration":21.741571,"end_time":"2024-09-04T08:57:21.770055","exception":false,"start_time":"2024-09-04T08:57:00.028484","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# basic\n","import sys, os, re, torch, werpy, jiwer, wandb\n","from collections import Counter\n","import pandas as pd\n","from tqdm import tqdm\n","import numpy as np\n","from typing import Literal\n","\n","# ml commons\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","# devie septup\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# utils setup\n","current_directory = os.getcwd()\n","root_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n","BASE_PATH = \"/kaggle/input/lmr-generated\"\n","sys.path.append(BASE_PATH+\"utils\")\n","os.environ[\"WANDB_PROJECT\"] = \"fine-tune-bert-for-lmr-2ep-t16v8-fullDF.ipynb\"\n","os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n","os.environ['CUDA_LAUNCH_BLOCKING']=\"1\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T04:22:00.421365Z","iopub.status.busy":"2024-09-06T04:22:00.420724Z","iopub.status.idle":"2024-09-06T04:22:00.426662Z","shell.execute_reply":"2024-09-06T04:22:00.425682Z","shell.execute_reply.started":"2024-09-06T04:22:00.421324Z"},"trusted":true},"outputs":[],"source":["# custom utils\n","#from utils.io import Predictions\n","#from utils.metrics import LMR_Metrics\n","#from utils.io import LMR_BILOU_Scrapper, LMR_JSON_Scrapper\n","#from utils.preprocessing import Preprocess\n","#from utils.stratify import MultiLabelNERStratify"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011625,"end_time":"2024-09-04T08:57:21.793718","exception":false,"start_time":"2024-09-04T08:57:21.782093","status":"completed"},"tags":[]},"source":["### **Helpers**"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:07:44.697770Z","iopub.status.busy":"2024-09-06T07:07:44.697322Z","iopub.status.idle":"2024-09-06T07:07:44.724075Z","shell.execute_reply":"2024-09-06T07:07:44.723118Z","shell.execute_reply.started":"2024-09-06T07:07:44.697731Z"},"trusted":true},"outputs":[],"source":["# Helper 1\n","def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n","    tokenized_sentence, labels = [], []\n","    for word, label in zip(sentence.split(), text_labels.split(\" \")):\n","        tokenized_word = tokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","        tokenized_sentence.extend(tokenized_word)\n","        labels.extend([label] * n_subwords)\n","    return tokenized_sentence, labels\n","\n","# Helper 2\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        sentence = self.data.words[index]  \n","        word_labels = self.data.labels[index]  \n","        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n","        \n","        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"]\n","        labels.insert(0, \"O\")\n","        labels.insert(-1, \"O\")\n","\n","        if len(tokenized_sentence) > self.max_len:\n","            tokenized_sentence = tokenized_sentence[:self.max_len]\n","            labels = labels[:self.max_len]\n","        else:\n","            tokenized_sentence += ['[PAD]'] * (self.max_len - len(tokenized_sentence))\n","            labels += [\"O\"] * (self.max_len - len(labels))\n","\n","        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n","        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n","        label_ids = [label2id[label] for label in labels]\n","        \n","        return {\n","            'input_ids': torch.tensor(ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(attn_mask, dtype=torch.long),\n","            'labels': torch.tensor(label_ids, dtype=torch.long)\n","        }\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","# Helper 3\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","\n","    # For WER Metrics\n","    true_loc, pred_loc = [], []\n","    for i in range(len(labels)):\n","        label_decoded = [id2label[pred] for pred in labels[i]]\n","        pred_decoded  = [id2label[pred] for pred in preds[i]]\n","        filtered_pred  = \" \".join([word for word in pred_decoded if word not in ['O', '[CLS]', '[SEP]', '[PAD]']])\n","        filtered_label = \" \".join([word for word in label_decoded if word not in ['O', '[CLS]', '[SEP]', '[PAD]']])\n","        true_loc.append(filtered_label if filtered_label != \"\" else \"Empty\")\n","        pred_loc.append(filtered_pred if filtered_pred != \"\" else \"Empty\")\n","    wer_scores  = werpy.wers(true_loc, pred_loc)\n","    average_wer = sum(wer_scores) / len(wer_scores)\n","    # print(average_wer)\n","    # print(true_loc)\n","    # print(pred_loc)\n","\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels.flatten(), preds.flatten(), average='weighted')\n","    acc = accuracy_score(labels.flatten(), preds.flatten())\n","    return {\n","        'accuracy'  : acc,\n","        'precision' : precision,\n","        'recall'    : recall,\n","        'f1'        : f1,\n","        'wer'       : average_wer\n","    }\n","\n","# Helper 4\n","def make_infererence(sentences, model, tokenizer, max_len=100, with_extra=False):\n","    model.eval()\n","    results = []\n","    extra_results = []\n","    \n","    for sentence in tqdm(sentences):\n","        tokenized_sentence = tokenizer(\n","            sentence.split(),\n","            is_split_into_words=True,\n","            return_offsets_mapping=False,\n","            padding='max_length',\n","            truncation=True,\n","            max_length=max_len,\n","            return_tensors=\"pt\"\n","        )\n","        \n","        input_ids = tokenized_sentence['input_ids'].to(device)\n","        attention_mask = tokenized_sentence['attention_mask'].to(device)        \n","        with torch.no_grad():\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        \n","        logits = outputs.logits\n","        predictions = torch.argmax(logits, dim=2)  # Get the index of the highest logit for each token\n","        \n","        pred_labels = [id2label[pred.item()] for pred in predictions[0]]\n","        tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n","        filtered_tokens = [\n","            token for token, label in zip(tokens, pred_labels)\n","            if label != 'O' and token not in ['[CLS]', '[SEP]', '[PAD]']\n","        ]\n","        filtered_labels = [\n","            label for token, label in zip(tokens, pred_labels)\n","            if label != 'O' and token not in ['[CLS]', '[SEP]', '[PAD]']\n","        ]\n","        \n","        results.append(\" \".join(filtered_tokens))\n","        extra_results.append(filtered_labels)\n","        \n","    if with_extra:\n","        return results, extra_results\n","    return results\n","\n","# Helper 5\n","def compute_wer_eval(df, col1='location', col2='prediction'):\n","    def calculate_wer(row):\n","        return jiwer.wer(str(row[col1]), str(row[col2]))\n","    df['WER'] = df.apply(calculate_wer, axis=1)\n","    average_wer = df['WER'].mean()\n","    return df, average_wer"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:07:45.071464Z","iopub.status.busy":"2024-09-06T07:07:45.071094Z","iopub.status.idle":"2024-09-06T07:07:45.097944Z","shell.execute_reply":"2024-09-06T07:07:45.096954Z","shell.execute_reply.started":"2024-09-06T07:07:45.071427Z"},"trusted":true},"outputs":[],"source":["def find_indices(text, locations):\n","    try:\n","        if locations.strip() == '':\n","            return ' '\n","        words = locations.split()\n","        \n","        combinations = []\n","        for length in range(1, 4):\n","            for i in range(len(words) - length + 1):\n","                combination = ' '.join(words[i:i + length])\n","                combinations.append(combination)\n","        indices = []\n","        for comb in combinations:\n","            for match in re.finditer(re.escape(comb), text, re.IGNORECASE):\n","                indices.append((match.start(), match.end(), comb))\n","\n","        # keep only indices with the longest match. \n","        indices = sorted(indices, key=lambda x: len(x[2]), reverse=True)\n","        # drop duplicated start indices \n","        indices = [indices[0]] + [x for i, x in enumerate(indices[1:], 1) if x[0] not in [y[0] for y in indices[:i]]]\n","        # drop indices that are contained in other indices\n","        indices = [x for i, x in enumerate(indices) if not any(x[0] >= y[0] and x[1] <= y[1] for y in indices[:i] + indices[i+1:])]\n","\n","        # return group of words corresponding to the indices in text \n","        words_from_text = []\n","        for start, end, comb in indices:\n","            words_from_text.append(text[start:end])\n","    except IndexError: \n","        words_from_text = find_substring_indices(text, locations)\n","\n","    return \" \".join(sorted(set(words_from_text)))\n","\n","def find_substring_indices(text, locations):\n","    # Generate all possible substrings of the word\n","    substrings = [locations[i:j] for i in range(len(locations)) for j in range(i + 1, len(locations) + 1)]\n","    indices = []\n","    for substring in substrings:\n","        for match in re.finditer(re.escape(substring), text, re.IGNORECASE):\n","            indices.append((match.start(), match.end(), substring))\n","\n","    # keep only indices with the longest match.\n","    indices = sorted(indices, key=lambda x: len(x[2]), reverse=True)\n","\n","    # drop duplicated start indices\n","    indices = [indices[0]] + [x for i, x in enumerate(indices[1:], 1) if x[0] not in [y[0] for y in indices[:i]]]\n","\n","    # drop indices that are contained in other indices\n","    indices = [x for i, x in enumerate(indices) if not any(x[0] >= y[0] and x[1] <= y[1] for y in indices[:i] + indices[i+1:])]\n","\n","    # keep indices of words long of at least 2 characters\n","    indices = [x for x in indices if len(x[2]) >= 3]\n","\n","    # words_from_text \n","    words_from_text = []\n","    for start, end, substring in indices:\n","        words_from_text.append(substring)\n","\n","    # sort words_from_text\n","    words_from_text = sorted(words_from_text)\n","\n","    return words_from_text\n","\n","def heuristic_postprocess_1(row):\n","    _id    = row['tweet_id']\n","    text  = row['raw_prediction']\n","    tweet = row['text']\n","    \n","    \n","    # 1 - Clean Special char\n","    replacements = {\n","        \" ##\": \"\",\n","        \"##\": \"\",\n","        \",\": \"\",\n","        \"U . S .\": \"U.S.\",\n","        \"U . S\": \"U.S.\",\n","        \"U S\": \"U.S.\",\n","        \"L . A .\": \"L.A.\",\n","        \"L . A\": \"L.A.\",\n","        \"L A\": \"L.A.\",\n","        \"P . R .\": \"P.R.\",\n","        \"P . R\": \"P.R.\",\n","        \"P R\": \"P.R.\",\n","        \"N . C .\": \"N.C.\",\n","        \"N . N\": \"N.C.\",\n","        \"N C\": \"N.C.\",\n","        \"D . C .\": \"D.C.\",\n","        \"D . C\": \"D.C.\",\n","        \"D C\": \"D.C.\"\n","    }\n","    for word, replacement in replacements.items():\n","        text = text.replace(word, replacement)\n","     \n","    #\"\"\"\n","    # 2 - Special Replace\n","    text = re.sub(r'\\bM\\b', 'Md.', text)\n","    text = re.sub(r'\\bElliot\\b', '', text)\n","    text = re.sub(r'\\bMat\\b', 'Matti', text)\n","    text = re.sub(r'\\bSD\\b', 'SDMA', text)\n","    text = re.sub(r'\\bZ\\b', 'Zimba', text)\n","    text = re.sub(r'\\btt\\b', 'Hutt', text)\n","    text = re.sub(r'\\bbe\\b', 'Brooklyn', text)\n","    text = re.sub(r'\\bly\\b', 'welly', text)\n","    text = re.sub(r'\\bgree\\b', 'greece', text)\n","    text = re.sub(r'\\bAt\\b', 'Attica', text)\n","    \n","    \n","    # 3 - Join City or County or New as one word\n","    pattern1 = r'\\b(\\w+)\\s(city|CITY|City|county|COUNTY|County)\\b'\n","    pattern2 = r'\\b(New|NEW|new|United|United__Arabe|East)\\s(\\w+)\\b'\n","    def replace_func1(match):\n","        first_word = match.group(1)\n","        city_word = match.group(2)\n","        return f'{first_word}__{city_word}'\n","    def replace_func2(match):\n","        first_word = match.group(1)\n","        next_word = match.group(2)\n","        return f'{first_word}__{next_word}'\n","    text = re.sub(pattern1, replace_func1, text)\n","    text = re.sub(pattern2, replace_func2, text)\n","    \n","    # 4 - Remove repeated groups of words\n","    words = text.split()\n","    seen_words = set()\n","    unique_words = []\n","    for word in words:\n","        if word not in seen_words:\n","            seen_words.add(word)\n","            unique_words.append(word)\n","    \n","    # 5 - Sort location in Alphabetic order\n","    unique_words = [place.replace(\"__\", \" \") for place in unique_words]\n","    unique_words = sorted(unique_words)\n","    text = \" \".join(unique_words)\n","    \n","    # 6 - Remove words with length lower than 2\n","    text = \" \".join([word for word in text.split() if len(word) >= 2])\n","    #\"\"\"\n","    \n","    # Desiré processing\n","    #text = find_indices(tweet, text)\n","    \n","    # 7 - Return location\n","    if not isinstance(text, str) or not text.strip():\n","        return \" \"\n","    return text.strip()"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:07:45.441795Z","iopub.status.busy":"2024-09-06T07:07:45.441440Z","iopub.status.idle":"2024-09-06T07:07:45.469993Z","shell.execute_reply":"2024-09-06T07:07:45.469083Z","shell.execute_reply.started":"2024-09-06T07:07:45.441762Z"},"trusted":true},"outputs":[],"source":["class DynamicTextAligner:\n","    \"\"\"\n","    **LMR-Text Local Alignment Search Class**\n","    Idea: The idea is to inspire from BLAST, Basic Local Alignment Search Tool for genomics data \n","    and develop light and simple alignment search tool for LMR text. We have to take raw \n","    prediction from the model and find a match within the initl tweet to identify the correct \n","    word the model is trying to predict.\n","    \"\"\"\n","    def __init__(self, text, subtext):\n","        self.text = text\n","        self.subtext = subtext\n","        self.subtext_chunks = subtext.split()\n","        self.chunk_ids = list(range(len(self.subtext_chunks)))\n","        self.text_words_offsets = self._get_text_word_offsets()\n","    \n","    def _get_text_word_offsets(self):\n","        words = self.text.split()\n","        word_offsets = []\n","        current_position = 0\n","        \n","        for word in words:\n","            start_offset = self.text.find(word, current_position)\n","            end_offset = start_offset + len(word) - 1\n","            word_offsets.append({\n","                'word': word,\n","                'start_offset': start_offset,\n","                'end_offset': end_offset\n","            })\n","            current_position = end_offset + 1\n","\n","        return word_offsets\n","    \n","    def find_chunk_positions(self):\n","        results = []\n","        text_len = len(self.text)\n","\n","        current_pos = 0\n","        for idx, chunk in enumerate(self.subtext_chunks):\n","            chunk_len = len(chunk)\n","            \n","            # Search for the chunk starting from the current position\n","            match = None\n","            for i in range(current_pos, text_len - chunk_len + 1):\n","                if self.text[i:i + chunk_len] == chunk:\n","                    match = (i, i + chunk_len - 1)\n","                    break\n","            \n","            if match:\n","                start_offset, end_offset = match\n","                results.append({\n","                    'chunk_id': idx,\n","                    'chunk': chunk,\n","                    'start_offset': start_offset,\n","                    'end_offset': end_offset\n","                })\n","                current_pos = end_offset + 1\n","\n","        return results\n","    \n","    def merge_consecutive_words(self, words):\n","        merged_words = []\n","        i = 0\n","        while i < len(words):\n","            current_word = words[i]\n","            if i + 1 < len(words):\n","                next_word = words[i + 1]\n","                if current_word['end_offset'] + 2 == next_word['start_offset']:\n","                    merged_word = {\n","                        'word': f\"{current_word['word']} {next_word['word']}\",\n","                        'start_offset': current_word['start_offset'],\n","                        'end_offset': next_word['end_offset']\n","                    }\n","                    merged_words.append(merged_word)\n","                    i += 2\n","                    continue\n","            merged_words.append(current_word)\n","            i += 1\n","        return merged_words\n","\n","    def heuristic_processing(self, merged_words):\n","        # 1 - Replace special cases\n","        punctuations = [\",\", \";\", \":\", \"#\", \"(\", \")\", \"\\\"\", \"[\", \"]\", \"?\"]\n","        output = [word['word'].split(\"’\")[0] for word in merged_words]\n","        output = [word.replace(\".,\", \".\") for word in output]\n","        output = [subword for word in output for subword in word.split('/')]\n","        words  = [word.translate(str.maketrans('', '', ''.join(punctuations))) for word in output]\n","\n","        # 2 - Handle hyphens and capital letters\n","        processed_words = []\n","        for word in words:\n","            if word.isupper():\n","                processed_words.append(word)\n","            else:\n","                processed_word = word.replace(\"-\", \" \")\n","                processed_words.append(processed_word)\n","                \n","        # 3 - Process dots in words\n","        final_words = []\n","        for word in processed_words:\n","            if \".\" in word and word.count(\".\") < 2:\n","                if word.endswith(\"Md.\"):\n","                    final_words.append(word)\n","                else:\n","                    final_words.append(word.replace(\".\", \"\"))\n","            else:\n","                final_words.append(word)\n","                \n","        final_words = sorted(final_words)\n","        output = \" \".join(final_words)\n","        return output\n","\n","    def get_alignment(self, mode: Literal[\"dict\", \"flat\", \"groups\", \"flat_groups\", \"flat_sorted_groups\", \"flat_sorted_groups+heur\"] = \"dict\"):\n","        matches = self.find_chunk_positions()\n","        aligned_words = []\n","        remaining_word_offsets = self.text_words_offsets.copy()\n","\n","        for match in matches:\n","            chunk_start = match['start_offset']\n","            chunk_end = match['end_offset']\n","\n","            for i, word_info in enumerate(remaining_word_offsets):\n","                word_start = word_info['start_offset']\n","                word_end = word_info['end_offset']\n","\n","                if word_start <= chunk_start and word_end >= chunk_end:\n","                    aligned_words.append(word_info)\n","\n","                    del remaining_word_offsets[i]\n","                    break\n","\n","        if mode == \"flat\":\n","            output = [word['word'] for word in aligned_words]\n","        elif mode == \"groups\":\n","            output = self.merge_consecutive_words(aligned_words)\n","        elif mode == \"flat_groups\":\n","            merged_words = self.merge_consecutive_words(aligned_words)\n","            output = \" \".join([word['word'] for word in merged_words])\n","        elif mode == \"flat_sorted_groups\":\n","            merged_words = self.merge_consecutive_words(aligned_words)\n","            output = \" \".join(sorted([word['word'] for word in merged_words]))\n","        elif mode == \"flat_sorted_groups+heur\":\n","            merged_words = self.merge_consecutive_words(aligned_words)\n","            output = self.heuristic_processing(merged_words)\n","        else:\n","            output = aligned_words\n","        return output\n","\n","    \n","    def display_results(self):\n","        matches = self.find_chunk_positions()\n","        for match in matches:\n","            print(f\"Chunk ID: {match['chunk_id']}, Chunk: '{match['chunk']}', Start: {match['start_offset']}, End: {match['end_offset']}\")\n","            \n","\n","def TLAST_postprocess(row):\n","    generated_text  = row['raw_prediction']\n","    targeted_text   = row['text']\n","    \n","    if not isinstance(generated_text, str) or not generated_text.strip():\n","        return \" \"\n","    \n","    # Clean Special Clean\n","    replacements = {\n","        \" ##\": \"\",\n","        \"##\": \"\",\n","    }\n","    for word, replacement in replacements.items():\n","        generated_text = generated_text.replace(word, replacement)\n","    \n","    # Call TLAST\n","    cleaned_text = DynamicTextAligner(targeted_text, generated_text).get_alignment(\n","        mode=\"flat_sorted_groups+heur\"\n","    )\n","    return cleaned_text.strip() "]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.01146,"end_time":"2024-09-04T08:57:21.877885","exception":false,"start_time":"2024-09-04T08:57:21.866425","status":"completed"},"tags":[]},"source":["### **Data preparation**"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:09:22.552453Z","iopub.status.busy":"2024-09-06T07:09:22.551975Z","iopub.status.idle":"2024-09-06T07:09:22.656405Z","shell.execute_reply":"2024-09-06T07:09:22.655635Z","shell.execute_reply.started":"2024-09-06T07:09:22.552414Z"},"trusted":true},"outputs":[],"source":["# Train\n","train_dataset = pd.read_csv('/kaggle/input/lmr-full/train_bilou.csv')\n","\n","# Dev\n","test_dataset = pd.read_csv('/kaggle/input/lmr-full/dev_bilou.csv')\n","\n","# Full\n","data = pd.concat([train_dataset, test_dataset])"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:09:23.299453Z","iopub.status.busy":"2024-09-06T07:09:23.298643Z","iopub.status.idle":"2024-09-06T07:09:23.310448Z","shell.execute_reply":"2024-09-06T07:09:23.309350Z","shell.execute_reply.started":"2024-09-06T07:09:23.299411Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Flash floods struck a Maryland city on Sunday ...</td>\n","      <td>O O O O U-STATE O O O O O O O O O O O O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>State of emergency declared for Maryland flood...</td>\n","      <td>O O O O O U-STATE O O O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Other parts of Maryland also saw significant d...</td>\n","      <td>O O O U-STATE O O O O O O O O O U-CITY O O O O...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Catastrophic Flooding Slams Ellicott City Mary...</td>\n","      <td>O O O U-CITY U-CITY U-STATE O O O O O O O O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>WATCH 1 missing after flash FLOODING devastate...</td>\n","      <td>O O O O O O O U-CITY U-CITY U-STATE O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               words  \\\n","0  Flash floods struck a Maryland city on Sunday ...   \n","1  State of emergency declared for Maryland flood...   \n","2  Other parts of Maryland also saw significant d...   \n","3  Catastrophic Flooding Slams Ellicott City Mary...   \n","4  WATCH 1 missing after flash FLOODING devastate...   \n","\n","                                              labels  \n","0            O O O O U-STATE O O O O O O O O O O O O  \n","1                            O O O O O U-STATE O O O  \n","2  O O O U-STATE O O O O O O O O O U-CITY O O O O...  \n","3        O O O U-CITY U-CITY U-STATE O O O O O O O O  \n","4              O O O O O O O U-CITY U-CITY U-STATE O  "]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011489,"end_time":"2024-09-04T08:57:22.777804","exception":false,"start_time":"2024-09-04T08:57:22.766315","status":"completed"},"tags":[]},"source":["### **Modeling preparation**"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011463,"end_time":"2024-09-04T08:57:22.800976","exception":false,"start_time":"2024-09-04T08:57:22.789513","status":"completed"},"tags":[]},"source":["- **Prepare custom label mappings**: \n","\n","<div style=\"padding-left: 2.5em;\">Before fine-tuning, it’s essential to map the location mention labels from the BILOU format to a format that BERT can understand. This involves converting categorical labels (e.g., `B-CITY`,`B-COUNTY`, ...) into integer IDs, which the model will use during training. This mapping is critical because BERT outputs logits for each token, which are then converted back to these labels.</div>"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:09:26.368758Z","iopub.status.busy":"2024-09-06T07:09:26.367999Z","iopub.status.idle":"2024-09-06T07:09:26.393752Z","shell.execute_reply":"2024-09-06T07:09:26.392781Z","shell.execute_reply.started":"2024-09-06T07:09:26.368718Z"},"papermill":{"duration":0.041435,"end_time":"2024-09-04T08:57:22.877274","exception":false,"start_time":"2024-09-04T08:57:22.835839","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/plain":["{'B-CITY',\n"," 'B-COUNTRY',\n"," 'B-COUNTY',\n"," 'B-DISTRICT',\n"," 'B-HUMAN-MADE',\n"," 'B-ISLAND',\n"," 'B-NATURAL',\n"," 'B-NEIGHBORHOOD',\n"," 'B-OTHER',\n"," 'B-ROAD',\n"," 'B-STATE',\n"," 'I-CITY',\n"," 'I-HUMAN-MADE',\n"," 'I-ISLAND',\n"," 'I-NATURAL',\n"," 'I-OTHER',\n"," 'I-ROAD',\n"," 'I-STATE',\n"," 'L-CITY',\n"," 'L-CONTINENT',\n"," 'L-COUNTRY',\n"," 'L-COUNTY',\n"," 'L-DISTRICT',\n"," 'L-HUMAN-MADE',\n"," 'L-ISLAND',\n"," 'L-NATURAL',\n"," 'L-OTHER',\n"," 'L-ROAD',\n"," 'L-STATE',\n"," 'O',\n"," 'U-CITY',\n"," 'U-CONTINENT',\n"," 'U-COUNTRY',\n"," 'U-COUNTY',\n"," 'U-DISTRICT',\n"," 'U-HUMAN-MADE',\n"," 'U-ISLAND',\n"," 'U-NATURAL',\n"," 'U-NEIGHBORHOOD',\n"," 'U-OTHER',\n"," 'U-ROAD',\n"," 'U-STATE'}"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["# Extract unique tags from word labels\n","tags = set(\" \".join(data.labels).split(' '))\n","\n","# Create label to ID and ID to label mappings\n","label2id = {k: v for v, k in enumerate(tags)}\n","id2label = {v: k for v, k in enumerate(tags)}\n","\n","# Get a look of tags\n","tags"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.012279,"end_time":"2024-09-04T08:57:22.901876","exception":false,"start_time":"2024-09-04T08:57:22.889597","status":"completed"},"tags":[]},"source":["### **Setup the model and tokenizer**\n","\n","- **Pretrained model for huggingface**: \n","\n","<div style=\"padding-left: 2.5em;\">We retrieve the tokenizer and the model from Huggingface's library of pre-trained models. This allows us to leverage a model that has already been fine-tuned for a specific task, such as Named Entity Recognition (NER). The tokenizer helps preprocess the input text by converting it into a format that the model can interpret, while the model is used to make predictions based on this input.</div>"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:09:33.088329Z","iopub.status.busy":"2024-09-06T07:09:33.087921Z","iopub.status.idle":"2024-09-06T07:09:44.640050Z","shell.execute_reply":"2024-09-06T07:09:44.639043Z","shell.execute_reply.started":"2024-09-06T07:09:33.088275Z"},"papermill":{"duration":37.394929,"end_time":"2024-09-04T08:58:00.309376","exception":false,"start_time":"2024-09-04T08:57:22.914447","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of the model checkpoint at rsuwaileh/IDRISI-LMR-EN-random-typebased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at rsuwaileh/IDRISI-LMR-EN-random-typebased and are newly initialized because the shapes did not match:\n","- classifier.weight: found shape torch.Size([49, 1024]) in the checkpoint and torch.Size([42, 1024]) in the model instantiated\n","- classifier.bias: found shape torch.Size([49]) in the checkpoint and torch.Size([42]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=1024, out_features=42, bias=True)\n",")"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["base_model = \"rsuwaileh/IDRISI-LMR-EN-random-typebased\" #\"FacebookAI/roberta-base\" #\"bert-large-uncased\"\n","\n","# pull model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained(base_model)\n","model = BertForTokenClassification.from_pretrained(\n","    base_model, #\"bert-large-uncased\",\n","    num_labels=len(id2label),\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes=True\n",")\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.012863,"end_time":"2024-09-04T08:58:00.335552","exception":false,"start_time":"2024-09-04T08:58:00.322689","status":"completed"},"tags":[]},"source":["- **DataCollator**: \n","\n","<div style=\"padding-left: 2.5em;\">\n","A custom dataset class is created to handle the input data, applying tokenization and ensuring that sequences are properly padded or truncated to fit the model’s expected input size. The `DataCollatorForTokenClassification` from the Hugging Face `transformers` library is used to dynamically pad batches during training, making the process efficient and preventing data leakage between samples.\n","</div>"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:09:44.642354Z","iopub.status.busy":"2024-09-06T07:09:44.641909Z","iopub.status.idle":"2024-09-06T07:09:44.647751Z","shell.execute_reply":"2024-09-06T07:09:44.646662Z","shell.execute_reply.started":"2024-09-06T07:09:44.642283Z"},"papermill":{"duration":0.020763,"end_time":"2024-09-04T08:58:00.369561","exception":false,"start_time":"2024-09-04T08:58:00.348798","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForTokenClassification(tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["- Create custom datasets for training and testing"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:09:51.235768Z","iopub.status.busy":"2024-09-06T07:09:51.235365Z","iopub.status.idle":"2024-09-06T07:09:51.266751Z","shell.execute_reply":"2024-09-06T07:09:51.265689Z","shell.execute_reply.started":"2024-09-06T07:09:51.235733Z"},"trusted":true},"outputs":[{"data":{"text/plain":["93"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["data['labels'].apply(lambda x: len(x.split(\" \"))).max()"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:09:52.775200Z","iopub.status.busy":"2024-09-06T07:09:52.774227Z","iopub.status.idle":"2024-09-06T07:09:52.780277Z","shell.execute_reply":"2024-09-06T07:09:52.779077Z","shell.execute_reply.started":"2024-09-06T07:09:52.775154Z"},"papermill":{"duration":0.021484,"end_time":"2024-09-04T08:58:00.404285","exception":false,"start_time":"2024-09-04T08:58:00.382801","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["MAX_LEN = 100\n","\n","training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n","testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"]},{"cell_type":"markdown","metadata":{},"source":["- Define training parameters"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:10:03.897234Z","iopub.status.busy":"2024-09-06T07:10:03.896800Z","iopub.status.idle":"2024-09-06T07:10:03.901753Z","shell.execute_reply":"2024-09-06T07:10:03.900715Z","shell.execute_reply.started":"2024-09-06T07:10:03.897196Z"},"papermill":{"duration":0.019737,"end_time":"2024-09-04T08:58:00.437322","exception":false,"start_time":"2024-09-04T08:58:00.417585","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 16\n","EPOCHS = 2"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.01281,"end_time":"2024-09-04T08:58:00.463827","exception":false,"start_time":"2024-09-04T08:58:00.451017","status":"completed"},"tags":[]},"source":["- Setup trainer"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:10:06.712085Z","iopub.status.busy":"2024-09-06T07:10:06.711376Z","iopub.status.idle":"2024-09-06T07:10:06.762830Z","shell.execute_reply":"2024-09-06T07:10:06.761800Z","shell.execute_reply.started":"2024-09-06T07:10:06.712043Z"},"papermill":{"duration":0.064057,"end_time":"2024-09-04T08:58:00.540534","exception":false,"start_time":"2024-09-04T08:58:00.476477","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n","    per_device_eval_batch_size=VALID_BATCH_SIZE,\n","    warmup_steps=25,\n","    weight_decay=0.001,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    eval_strategy=\"steps\",\n","    eval_steps=25,\n","    save_steps=50,\n","    save_total_limit=2,\n","    gradient_accumulation_steps=4,\n","    fp16=True,\n","    report_to=[\"none\"],\n","    learning_rate=2e-5,\n","    lr_scheduler_type=\"cosine\",\n","    metric_for_best_model=\"wer\",\n","    greater_is_better=False,\n","    load_best_model_at_end=True\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=training_set,\n","    eval_dataset=testing_set,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"papermill":{"duration":0.0128,"end_time":"2024-09-04T08:58:00.566556","exception":false,"start_time":"2024-09-04T08:58:00.553756","status":"completed"},"tags":[]},"source":["### **Fine-tuning**"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:10:08.208657Z","iopub.status.busy":"2024-09-06T07:10:08.208221Z","iopub.status.idle":"2024-09-06T07:30:36.959654Z","shell.execute_reply":"2024-09-06T07:30:36.958701Z","shell.execute_reply.started":"2024-09-06T07:10:08.208616Z"},"papermill":{"duration":15756.054027,"end_time":"2024-09-04T13:20:36.659148","exception":false,"start_time":"2024-09-04T08:58:00.605121","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='224' max='224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [224/224 20:23, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Wer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>1.206200</td>\n","      <td>0.105004</td>\n","      <td>0.980073</td>\n","      <td>0.960557</td>\n","      <td>0.980073</td>\n","      <td>0.970217</td>\n","      <td>0.720817</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.039700</td>\n","      <td>0.045860</td>\n","      <td>0.990151</td>\n","      <td>0.988225</td>\n","      <td>0.990151</td>\n","      <td>0.989071</td>\n","      <td>0.303611</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.036600</td>\n","      <td>0.037643</td>\n","      <td>0.991683</td>\n","      <td>0.989633</td>\n","      <td>0.991683</td>\n","      <td>0.990592</td>\n","      <td>0.275782</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.030900</td>\n","      <td>0.035468</td>\n","      <td>0.991848</td>\n","      <td>0.990696</td>\n","      <td>0.991848</td>\n","      <td>0.991120</td>\n","      <td>0.295543</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.026600</td>\n","      <td>0.035281</td>\n","      <td>0.992135</td>\n","      <td>0.991118</td>\n","      <td>0.992135</td>\n","      <td>0.991480</td>\n","      <td>0.286800</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.024700</td>\n","      <td>0.034114</td>\n","      <td>0.992087</td>\n","      <td>0.991089</td>\n","      <td>0.992087</td>\n","      <td>0.991509</td>\n","      <td>0.290454</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.027400</td>\n","      <td>0.034001</td>\n","      <td>0.992218</td>\n","      <td>0.991129</td>\n","      <td>0.992218</td>\n","      <td>0.991602</td>\n","      <td>0.283210</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.023700</td>\n","      <td>0.033455</td>\n","      <td>0.992184</td>\n","      <td>0.991099</td>\n","      <td>0.992184</td>\n","      <td>0.991572</td>\n","      <td>0.285779</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"data":{"text/plain":["TrainOutput(global_step=224, training_loss=0.22873996131654298, metrics={'train_runtime': 1227.7064, 'train_samples_per_second': 23.445, 'train_steps_per_second': 0.182, 'total_flos': 5200013185641600.0, 'train_loss': 0.22873996131654298, 'epoch': 1.991111111111111})"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["### **Eval on new train**"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:30:36.962203Z","iopub.status.busy":"2024-09-06T07:30:36.961510Z","iopub.status.idle":"2024-09-06T07:30:37.079245Z","shell.execute_reply":"2024-09-06T07:30:37.078357Z","shell.execute_reply.started":"2024-09-06T07:30:36.962157Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(16448, 3)"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(\"/kaggle/input/lmr-full-train/full_train_1.csv\")\n","train = train[~train['text'].isna()]\n","train.shape"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:30:37.080666Z","iopub.status.busy":"2024-09-06T07:30:37.080365Z","iopub.status.idle":"2024-09-06T07:48:33.864584Z","shell.execute_reply":"2024-09-06T07:48:33.863535Z","shell.execute_reply.started":"2024-09-06T07:30:37.080630Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 16448/16448 [17:56<00:00, 15.28it/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>text</th>\n","      <th>location</th>\n","      <th>raw_prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>ID_1001136696589631488</td>\n","      <td>Flash floods struck a Maryland city on Sunday,...</td>\n","      <td>Maryland</td>\n","      <td>Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ID_1001136950345109504</td>\n","      <td>State of emergency declared for Maryland flood...</td>\n","      <td>Maryland</td>\n","      <td>Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ID_1001137334056833024</td>\n","      <td>Other parts of Maryland also saw significant d...</td>\n","      <td>Baltimore Maryland</td>\n","      <td>Maryland Baltimore Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ID_1001138374923579392</td>\n","      <td>Catastrophic Flooding Slams Ellicott City, Mar...</td>\n","      <td>Ellicott City Maryland</td>\n","      <td>El ##lic ##ott City Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ID_1001138377717157888</td>\n","      <td>WATCH: 1 missing after flash #FLOODING devasta...</td>\n","      <td>Ellicott City Maryland</td>\n","      <td>El ##lic ##ott City Maryland</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 tweet_id                                               text  \\\n","1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday,...   \n","2  ID_1001136950345109504  State of emergency declared for Maryland flood...   \n","3  ID_1001137334056833024  Other parts of Maryland also saw significant d...   \n","4  ID_1001138374923579392  Catastrophic Flooding Slams Ellicott City, Mar...   \n","5  ID_1001138377717157888  WATCH: 1 missing after flash #FLOODING devasta...   \n","\n","                 location                raw_prediction  \n","1                Maryland                      Maryland  \n","2                Maryland                      Maryland  \n","3      Baltimore Maryland   Maryland Baltimore Maryland  \n","4  Ellicott City Maryland  El ##lic ##ott City Maryland  \n","5  Ellicott City Maryland  El ##lic ##ott City Maryland  "]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["train_predictions = make_infererence(train.text.to_list(), trainer.model, tokenizer)\n","train['raw_prediction'] = train_predictions\n","train.head()"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:48:33.868540Z","iopub.status.busy":"2024-09-06T07:48:33.867824Z","iopub.status.idle":"2024-09-06T07:48:34.972352Z","shell.execute_reply":"2024-09-06T07:48:34.971355Z","shell.execute_reply.started":"2024-09-06T07:48:33.868498Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1.0319958995537053"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["_, average_wer = compute_wer_eval(train, col2='raw_prediction')\n","average_wer"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:48:34.974236Z","iopub.status.busy":"2024-09-06T07:48:34.973870Z","iopub.status.idle":"2024-09-06T07:48:36.910360Z","shell.execute_reply":"2024-09-06T07:48:36.909182Z","shell.execute_reply.started":"2024-09-06T07:48:34.974198Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.4624318651005626"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["train['prediction'] = train.apply(TLAST_postprocess, axis=1)\n","_, average_wer = compute_wer_eval(train, col2='prediction')\n","average_wer"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:48:36.912445Z","iopub.status.busy":"2024-09-06T07:48:36.912031Z","iopub.status.idle":"2024-09-06T07:48:38.710277Z","shell.execute_reply":"2024-09-06T07:48:38.709065Z","shell.execute_reply.started":"2024-09-06T07:48:36.912407Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0.43409873793891046"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["#train['prediction'] = train.apply(TLAST_postprocess, axis=1)\n","train['prediction'] = train.apply(heuristic_postprocess_1, axis=1)\n","_, average_wer = compute_wer_eval(train, col2='prediction')\n","average_wer"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:48:38.712304Z","iopub.status.busy":"2024-09-06T07:48:38.711864Z","iopub.status.idle":"2024-09-06T07:48:38.728230Z","shell.execute_reply":"2024-09-06T07:48:38.727361Z","shell.execute_reply.started":"2024-09-06T07:48:38.712248Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>text</th>\n","      <th>location</th>\n","      <th>raw_prediction</th>\n","      <th>WER</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>ID_1001136696589631488</td>\n","      <td>Flash floods struck a Maryland city on Sunday,...</td>\n","      <td>Maryland</td>\n","      <td>Maryland</td>\n","      <td>0.0</td>\n","      <td>Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ID_1001136950345109504</td>\n","      <td>State of emergency declared for Maryland flood...</td>\n","      <td>Maryland</td>\n","      <td>Maryland</td>\n","      <td>0.0</td>\n","      <td>Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ID_1001137334056833024</td>\n","      <td>Other parts of Maryland also saw significant d...</td>\n","      <td>Baltimore Maryland</td>\n","      <td>Maryland Baltimore Maryland</td>\n","      <td>0.0</td>\n","      <td>Baltimore Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ID_1001138374923579392</td>\n","      <td>Catastrophic Flooding Slams Ellicott City, Mar...</td>\n","      <td>Ellicott City Maryland</td>\n","      <td>El ##lic ##ott City Maryland</td>\n","      <td>0.0</td>\n","      <td>Ellicott City Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ID_1001138377717157888</td>\n","      <td>WATCH: 1 missing after flash #FLOODING devasta...</td>\n","      <td>Ellicott City Maryland</td>\n","      <td>El ##lic ##ott City Maryland</td>\n","      <td>0.0</td>\n","      <td>Ellicott City Maryland</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>73066</th>\n","      <td>ID_916080760276299776</td>\n","      <td>Mexico City: at least a thousand buildings dam...</td>\n","      <td>Mexico City</td>\n","      <td>Mexico City</td>\n","      <td>0.0</td>\n","      <td>Mexico City</td>\n","    </tr>\n","    <tr>\n","      <th>73068</th>\n","      <td>ID_916125408059445248</td>\n","      <td>Rescue workers recover the body of the last pe...</td>\n","      <td>Mexico City</td>\n","      <td>Mexico City</td>\n","      <td>0.0</td>\n","      <td>Mexico City</td>\n","    </tr>\n","    <tr>\n","      <th>73069</th>\n","      <td>ID_916135932285341696</td>\n","      <td>Donate from Facebook to Mexico Earthquake Reli...</td>\n","      <td>Mexico</td>\n","      <td>Mexico</td>\n","      <td>0.0</td>\n","      <td>Mexico</td>\n","    </tr>\n","    <tr>\n","      <th>73070</th>\n","      <td>ID_916146805347356672</td>\n","      <td>We are helping our clients in Mexico recover f...</td>\n","      <td>Mexico</td>\n","      <td>Mexico</td>\n","      <td>0.0</td>\n","      <td>Mexico</td>\n","    </tr>\n","    <tr>\n","      <th>73071</th>\n","      <td>ID_916205068281462784</td>\n","      <td>Thanks @RFC_Charity @UNICEFMexico for the supp...</td>\n","      <td>Mexico</td>\n","      <td>Mexico</td>\n","      <td>0.0</td>\n","      <td>Mexico</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>16448 rows × 6 columns</p>\n","</div>"],"text/plain":["                     tweet_id  \\\n","1      ID_1001136696589631488   \n","2      ID_1001136950345109504   \n","3      ID_1001137334056833024   \n","4      ID_1001138374923579392   \n","5      ID_1001138377717157888   \n","...                       ...   \n","73066   ID_916080760276299776   \n","73068   ID_916125408059445248   \n","73069   ID_916135932285341696   \n","73070   ID_916146805347356672   \n","73071   ID_916205068281462784   \n","\n","                                                    text  \\\n","1      Flash floods struck a Maryland city on Sunday,...   \n","2      State of emergency declared for Maryland flood...   \n","3      Other parts of Maryland also saw significant d...   \n","4      Catastrophic Flooding Slams Ellicott City, Mar...   \n","5      WATCH: 1 missing after flash #FLOODING devasta...   \n","...                                                  ...   \n","73066  Mexico City: at least a thousand buildings dam...   \n","73068  Rescue workers recover the body of the last pe...   \n","73069  Donate from Facebook to Mexico Earthquake Reli...   \n","73070  We are helping our clients in Mexico recover f...   \n","73071  Thanks @RFC_Charity @UNICEFMexico for the supp...   \n","\n","                     location                raw_prediction  WER  \\\n","1                    Maryland                      Maryland  0.0   \n","2                    Maryland                      Maryland  0.0   \n","3          Baltimore Maryland   Maryland Baltimore Maryland  0.0   \n","4      Ellicott City Maryland  El ##lic ##ott City Maryland  0.0   \n","5      Ellicott City Maryland  El ##lic ##ott City Maryland  0.0   \n","...                       ...                           ...  ...   \n","73066             Mexico City                   Mexico City  0.0   \n","73068             Mexico City                   Mexico City  0.0   \n","73069                  Mexico                        Mexico  0.0   \n","73070                  Mexico                        Mexico  0.0   \n","73071                  Mexico                        Mexico  0.0   \n","\n","                   prediction  \n","1                    Maryland  \n","2                    Maryland  \n","3          Baltimore Maryland  \n","4      Ellicott City Maryland  \n","5      Ellicott City Maryland  \n","...                       ...  \n","73066             Mexico City  \n","73068             Mexico City  \n","73069                  Mexico  \n","73070                  Mexico  \n","73071                  Mexico  \n","\n","[16448 rows x 6 columns]"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["_"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:48:38.730979Z","iopub.status.busy":"2024-09-06T07:48:38.729936Z","iopub.status.idle":"2024-09-06T07:48:38.937696Z","shell.execute_reply":"2024-09-06T07:48:38.936830Z","shell.execute_reply.started":"2024-09-06T07:48:38.730921Z"},"trusted":true},"outputs":[],"source":["_.to_csv(\"train_inference_tlast3.csv\")"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-09-05T06:23:37.902898Z","iopub.status.busy":"2024-09-05T06:23:37.902405Z","iopub.status.idle":"2024-09-05T06:23:37.911865Z","shell.execute_reply":"2024-09-05T06:23:37.911123Z","shell.execute_reply.started":"2024-09-05T06:23:37.902859Z"}},"source":["### **Utils for autocorrect**"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:06:18.502797Z","iopub.status.busy":"2024-09-06T07:06:18.502018Z","iopub.status.idle":"2024-09-06T07:06:18.506779Z","shell.execute_reply":"2024-09-06T07:06:18.505735Z","shell.execute_reply.started":"2024-09-06T07:06:18.502756Z"},"trusted":true},"outputs":[],"source":["#from transformers import pipeline\n","#from tqdm import tqdm\n","#tqdm.pandas()\n","#fix_spelling = pipeline(\"text2text-generation\",model=\"oliverguhr/spelling-correction-english-base\", device=device)\n","\n","#def correct_spelling(text):\n","#    return fix_spelling(text, max_length=2048)[0]['generated_text']\n","\n","#test['fixed_text'] = test['text'].progress_apply(correct_spelling)\n","#test.head()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.65538,"end_time":"2024-09-04T13:36:11.752234","exception":false,"start_time":"2024-09-04T13:36:11.096854","status":"completed"},"tags":[]},"source":["### **Make prediction for Context**"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-09-06T07:48:38.939172Z","iopub.status.busy":"2024-09-06T07:48:38.938832Z","iopub.status.idle":"2024-09-06T07:48:38.975380Z","shell.execute_reply":"2024-09-06T07:48:38.974373Z","shell.execute_reply.started":"2024-09-06T07:48:38.939138Z"},"papermill":{"duration":0.69807,"end_time":"2024-09-04T13:36:13.155300","exception":false,"start_time":"2024-09-04T13:36:12.457230","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ID_1001154804658286592</td>\n","      <td>What is happening to the infrastructure in New...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ID_1001155505459486720</td>\n","      <td>SOLDER MISSING IN FLOOD.. PRAY FOR EDDISON HER...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ID_1001155756371136512</td>\n","      <td>RT @TIME: Police searching for missing person ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ID_1001159445194399744</td>\n","      <td>Flash Flood Tears Through Maryland Town For Se...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ID_1001164907587538944</td>\n","      <td>Ellicott City #FLOODING Pictures: Maryland Gov...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 tweet_id                                               text\n","0  ID_1001154804658286592  What is happening to the infrastructure in New...\n","1  ID_1001155505459486720  SOLDER MISSING IN FLOOD.. PRAY FOR EDDISON HER...\n","2  ID_1001155756371136512  RT @TIME: Police searching for missing person ...\n","3  ID_1001159445194399744  Flash Flood Tears Through Maryland Town For Se...\n","4  ID_1001164907587538944  Ellicott City #FLOODING Pictures: Maryland Gov..."]},"execution_count":97,"metadata":{},"output_type":"execute_result"}],"source":["test = pd.read_csv(\"/kaggle/input/lmr-full/test_dataset.csv\")\n","test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ids = test[\"tweet_id\"].values\n","tweets = test[\"text\"].values\n","\n","# Make prediction\n","test_predictions = make_infererence(tweets, trainer.model, trainer.tokenizer, max_len=MAX_LEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":165.902593,"end_time":"2024-09-04T13:38:59.705065","exception":false,"start_time":"2024-09-04T13:36:13.802472","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# submission df\n","test['raw_prediction'] = test_predictions\n","\n","# Some Quick postprocessing\n","test['prediction'] = test.apply(TLAST_postprocess, axis=1)\n","test.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Save file\n","test[['tweet_id', 'prediction']].to_csv(\"submission_bbbilou+heuristic1.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5646355,"sourceId":9321313,"sourceType":"datasetVersion"},{"datasetId":5646935,"sourceId":9322087,"sourceType":"datasetVersion"},{"datasetId":5647275,"sourceId":9322541,"sourceType":"datasetVersion"},{"datasetId":5651338,"sourceId":9327872,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":16963.297039,"end_time":"2024-09-04T13:39:11.404959","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-04T08:56:28.107920","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"12cc95c67db2413a956b439054d379ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14396cd2b60243df89e5c9facdd9e4b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18adc4f601fd453aab7f0db3c6006c22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9ab3140676e428a82efe168fe8a2c56","placeholder":"​","style":"IPY_MODEL_261a0da9fe2e4ed28c3dfc6d587ed707","value":" 232k/232k [00:00&lt;00:00, 12.3MB/s]"}},"19de9c83f4274d19a4da2158615a6c82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1af0a1ac3d3d4b33bdc55be45a1ebd54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f747e9ecd0344e7b31ee61d0e013e2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22177923f3284cdd8b5fd7864f8258a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f747e9ecd0344e7b31ee61d0e013e2d","placeholder":"​","style":"IPY_MODEL_849506128eaf43a6b33936a2a651c240","value":"config.json: 100%"}},"261a0da9fe2e4ed28c3dfc6d587ed707":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28e0fb070bcd49bf809fab70702d2efe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28fa81b43ce049738faa8a873cadadaa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"347d85815bde46fe94878d1d02ce8d15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22177923f3284cdd8b5fd7864f8258a7","IPY_MODEL_9d6213a5b659455c911bc26cec180359","IPY_MODEL_cadbe681538e40f8bb5625e263c44673"],"layout":"IPY_MODEL_9c366a43cbc8495b82689329926e9b83"}},"3f1e6db6b1b74cd0b1821102f99177d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f86be6bf412444287789978cc24a738","placeholder":"​","style":"IPY_MODEL_5a5dfa968ce247799c7ad4abf9254a0d","value":"tokenizer_config.json: 100%"}},"3f86be6bf412444287789978cc24a738":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c555d7d69f64a07ad910f8acbde9de5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"521b75650510473898b7cf8f93365fc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"555f31427c3142d0b1f634246a0f88e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a5dfa968ce247799c7ad4abf9254a0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c8aead566204d45af94989fa235d774":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cb0cb8fd5014ecc9713df2f88ee7e95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c8aead566204d45af94989fa235d774","placeholder":"​","style":"IPY_MODEL_28fa81b43ce049738faa8a873cadadaa","value":" 1.34G/1.34G [00:33&lt;00:00, 42.4MB/s]"}},"635bc918049d4ddcbe61088ba9d4ba76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65f0db0d0ef24ab1a29e46e8b2fb7dd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_943f317332ae4fe4abddfc8e8d7a6e7d","placeholder":"​","style":"IPY_MODEL_c008b5ade97947eba854bbee21696f8e","value":"model.safetensors: 100%"}},"6b10ba0946474c1c8899ce2628432319":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1af0a1ac3d3d4b33bdc55be45a1ebd54","placeholder":"​","style":"IPY_MODEL_14396cd2b60243df89e5c9facdd9e4b0","value":"tokenizer.json: 100%"}},"79ee4b3c84c24fdcb2fbb0ea45d05750":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7af8e709fb994237befe3a8731df307d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b6df7377ac34d2b969f7bb0d7e6e2ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7af8e709fb994237befe3a8731df307d","placeholder":"​","style":"IPY_MODEL_ddffd235e8b249c186457a29c12e9ac0","value":" 466k/466k [00:00&lt;00:00, 33.0MB/s]"}},"849506128eaf43a6b33936a2a651c240":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8848f31b0af74783aa7afc2b5beecd10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"943f317332ae4fe4abddfc8e8d7a6e7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"971189af43ff4f46886a7d06475b6de3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99f6a2b83cb9409597ca100d74e2b5ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bccbfcc1dc714501aa3e7ed22c57c209","placeholder":"​","style":"IPY_MODEL_f2afb732ce244d35b6e0ae49c09672a0","value":"vocab.txt: 100%"}},"9c366a43cbc8495b82689329926e9b83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d6213a5b659455c911bc26cec180359":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79ee4b3c84c24fdcb2fbb0ea45d05750","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c48fa5f405794c489cff23b639bd2ec5","value":571}},"a68a32d23e4b4018ab412aed928eafd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65f0db0d0ef24ab1a29e46e8b2fb7dd2","IPY_MODEL_b418e57c31a24583a3e9d8ffee66da44","IPY_MODEL_5cb0cb8fd5014ecc9713df2f88ee7e95"],"layout":"IPY_MODEL_cd43f894455b431f81325f2662de0888"}},"ab66683095f44d5b82e4ce40d13c4f8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28e0fb070bcd49bf809fab70702d2efe","placeholder":"​","style":"IPY_MODEL_f7406591d7354fa8b9390a5d57d2e443","value":" 48.0/48.0 [00:00&lt;00:00, 4.09kB/s]"}},"ae66ba0cf4764a75aa07e6acecf1615a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8848f31b0af74783aa7afc2b5beecd10","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5285f044d8e418e807c468bbed7e544","value":466062}},"b418e57c31a24583a3e9d8ffee66da44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19de9c83f4274d19a4da2158615a6c82","max":1344951957,"min":0,"orientation":"horizontal","style":"IPY_MODEL_971189af43ff4f46886a7d06475b6de3","value":1344951957}},"b5f638a0e89c4d8da6bee55dd2fc4d29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b939716fd1e74fc1a81aca75d27a52ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bba2448523154af083824efe43d32eb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b10ba0946474c1c8899ce2628432319","IPY_MODEL_ae66ba0cf4764a75aa07e6acecf1615a","IPY_MODEL_7b6df7377ac34d2b969f7bb0d7e6e2ab"],"layout":"IPY_MODEL_bf00cf2648a547d49b0239531776db57"}},"bccbfcc1dc714501aa3e7ed22c57c209":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf00cf2648a547d49b0239531776db57":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c008b5ade97947eba854bbee21696f8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c48fa5f405794c489cff23b639bd2ec5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cadbe681538e40f8bb5625e263c44673":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c555d7d69f64a07ad910f8acbde9de5","placeholder":"​","style":"IPY_MODEL_521b75650510473898b7cf8f93365fc3","value":" 571/571 [00:00&lt;00:00, 44.3kB/s]"}},"cbba1e13544f4ab097e9b7c4ed93d174":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e19643b5e12b456aaf7db1c682338c6d","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_635bc918049d4ddcbe61088ba9d4ba76","value":48}},"cd43f894455b431f81325f2662de0888":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7f2f867f0004129890fc40121495075":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f1e6db6b1b74cd0b1821102f99177d4","IPY_MODEL_cbba1e13544f4ab097e9b7c4ed93d174","IPY_MODEL_ab66683095f44d5b82e4ce40d13c4f8f"],"layout":"IPY_MODEL_12cc95c67db2413a956b439054d379ba"}},"ddffd235e8b249c186457a29c12e9ac0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0c8064285d74c0e8e2986e5294a92c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99f6a2b83cb9409597ca100d74e2b5ff","IPY_MODEL_e2ae0981bbab41e3a4daa19bad392a25","IPY_MODEL_18adc4f601fd453aab7f0db3c6006c22"],"layout":"IPY_MODEL_b939716fd1e74fc1a81aca75d27a52ee"}},"e19643b5e12b456aaf7db1c682338c6d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2ae0981bbab41e3a4daa19bad392a25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_555f31427c3142d0b1f634246a0f88e1","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5f638a0e89c4d8da6bee55dd2fc4d29","value":231508}},"e9ab3140676e428a82efe168fe8a2c56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2afb732ce244d35b6e0ae49c09672a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5285f044d8e418e807c468bbed7e544":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7406591d7354fa8b9390a5d57d2e443":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}
