{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 0.5em; background-color: #1876d1; color: #fff; font-weight: bold; font-size: 1.4em;\">\n",
    "    [Approach 1]  Location Mention Recognition - NER BERT Approach\n",
    "</div>\n",
    "\n",
    "In this Jupyter notebook, we will use Name Entity Recognition to extract from X (Twitter formely) tweets Location Mention from Emergency Situation.\n",
    "\n",
    "Note :\n",
    "* Do NER\n",
    "* Try BERT Model\n",
    "* Extract Location Mention\n",
    "\n",
    "---\n",
    "<b>#Microsoft Learn Challenge, #Zindi, #Hamad Bin Khalifa University </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 4 types of NER systems\n",
    "Dictionary-based. Dictionary-based NER systems reference terms listed in dictionaries to identify their presence in text. Dictionaries can be any collection of words related to a specific field or domain. You can create one yourself or use public sources such as databases. \n",
    "\n",
    "Rule-based. Rule-based NER systems rely on a set of instructions for extracting named entities from text. You must create the rules based on two types of instruction: pattern-based rules, which relate to word forms and structure, and context-based rules like “if a contraction such as Mr. or Ms. precedes a name, then that contraction is the person’s honorific title.” These rules can also be combined with dictionaries.\n",
    "\n",
    "Machine learning-based. Machine learning-based NER systems are based on statistical models designed to identify entity names. To develop an ML-based NER system, the machine learning model must be trained on annotated documents. Annotated documents have explanations that help the machine learn to produce entity names based on instruction and past experiences.\n",
    "\n",
    "Hybrid systems. Hybrid NER systems combine more than one of the approaches listed above. \n",
    " -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras<3.0.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow<2.16\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-macosx_12_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting tf-models-official<2.16\n",
      "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting mediapipe-model-maker\n",
      "  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow<2.16\n",
      "  Downloading tensorflow-2.13.0-cp38-cp38-macosx_12_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-macos==2.13.0 (from tensorflow<2.16)\n",
      "  Downloading tensorflow_macos-2.13.0-cp38-cp38-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading h5py-3.11.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading numpy-1.24.3-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/LMR/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow<2.16) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/LMR/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow<2.16) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/LMR/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow<2.16) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading grpcio-1.66.0-cp38-cp38-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-macos==2.13.0->tensorflow<2.16)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<3.0.0\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting Cython (from tf-models-official<2.16)\n",
      "  Using cached Cython-3.0.11-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting Pillow (from tf-models-official<2.16)\n",
      "  Downloading pillow-10.4.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting gin-config (from tf-models-official<2.16)\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-api-python-client>=1.6.7 (from tf-models-official<2.16)\n",
      "  Downloading google_api_python_client-2.142.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting immutabledict (from tf-models-official<2.16)\n",
      "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting kaggle>=1.3.9 (from tf-models-official<2.16)\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib (from tf-models-official<2.16)\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
      "Collecting oauth2client (from tf-models-official<2.16)\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opencv-python-headless (from tf-models-official<2.16)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting pandas>=0.22.0 (from tf-models-official<2.16)\n",
      "  Downloading pandas-2.0.3-cp38-cp38-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/anaconda3/envs/LMR/lib/python3.8/site-packages (from tf-models-official<2.16) (5.8.0)\n",
      "Collecting py-cpuinfo>=3.3.0 (from tf-models-official<2.16)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pycocotools (from tf-models-official<2.16)\n",
      "  Downloading pycocotools-2.0.7-cp38-cp38-macosx_10_9_universal2.whl.metadata (1.1 kB)\n",
      "Collecting pyyaml>=6.0.0 (from tf-models-official<2.16)\n",
      "  Downloading pyyaml-6.0.2.tar.gz (130 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu (from tf-models-official<2.16)\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting scipy>=0.19.1 (from tf-models-official<2.16)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl.metadata (53 kB)\n",
      "Collecting sentencepiece (from tf-models-official<2.16)\n",
      "  Downloading sentencepiece-0.2.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting seqeval (from tf-models-official<2.16)\n",
      "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-datasets (from tf-models-official<2.16)\n",
      "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tensorflow-hub>=0.6.0 (from tf-models-official<2.16)\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official<2.16)\n",
      "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
      "INFO: pip is looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-models-official<2.16\n",
      "  Downloading tf_models_official-2.14.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading tf_models_official-2.14.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading tf_models_official-2.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading tf_models_official-2.13.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading tf_models_official-2.13.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyyaml<5.4.0,>=5.1 (from tf-models-official<2.16)\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tf-models-official<2.16\n",
      "  Downloading tf_models_official-2.13.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyyaml<6.0,>=5.1 (from tf-models-official<2.16)\n",
      "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[48 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing lib3/PyYAML.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to lib3/PyYAML.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to lib3/PyYAML.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/envs/LMR/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/envs/LMR/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/envs/LMR/lib/python3.8/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 332, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 302, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/build_meta.py\", line 318, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 271, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/__init__.py\", line 111, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 184, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/_distutils/core.py\", line 200, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 964, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/dist.py\", line 948, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/_distutils/dist.py\", line 983, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/command/egg_info.py\", line 311, in run\n",
      "  \u001b[31m   \u001b[0m     self.find_sources()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/command/egg_info.py\", line 319, in find_sources\n",
      "  \u001b[31m   \u001b[0m     mm.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/command/egg_info.py\", line 540, in run\n",
      "  \u001b[31m   \u001b[0m     self.add_defaults()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/command/egg_info.py\", line 578, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     sdist.add_defaults(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/command/sdist.py\", line 105, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     super().add_defaults()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/_distutils/command/sdist.py\", line 250, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     self._add_defaults_ext()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/_distutils/command/sdist.py\", line 335, in _add_defaults_ext\n",
      "  \u001b[31m   \u001b[0m     self.filelist.extend(build_ext.get_source_files())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 201, in get_source_files\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/w8/b_cflrn97k9c15rcrn5t8mmr0000gn/T/pip-build-env-003g02p4/overlay/lib/python3.8/site-packages/setuptools/_distutils/cmd.py\", line 107, in __getattr__\n",
      "  \u001b[31m   \u001b[0m     raise AttributeError(attr)\n",
      "  \u001b[31m   \u001b[0m AttributeError: cython_sources\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"keras<3.0.0\" \"tensorflow<2.16\" \"tf-models-official<2.16\" mediapipe-model-maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstanza\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import stanza\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploring Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EllicottCity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136696589631488</td>\n",
       "      <td>Flash floods struck a Maryland city on Sunday,...</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001136950345109504</td>\n",
       "      <td>State of emergency declared for Maryland flood...</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001137334056833024</td>\n",
       "      <td>Other parts of Maryland also saw significant d...</td>\n",
       "      <td>Baltimore Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001138374923579392</td>\n",
       "      <td>Catastrophic Flooding Slams Ellicott City, Mar...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0  ID_1001136212718088192                                                NaN   \n",
       "1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday,...   \n",
       "2  ID_1001136950345109504  State of emergency declared for Maryland flood...   \n",
       "3  ID_1001137334056833024  Other parts of Maryland also saw significant d...   \n",
       "4  ID_1001138374923579392  Catastrophic Flooding Slams Ellicott City, Mar...   \n",
       "\n",
       "                 location  \n",
       "0            EllicottCity  \n",
       "1                Maryland  \n",
       "2                Maryland  \n",
       "3      Baltimore Maryland  \n",
       "4  Ellicott City Maryland  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/Train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id        0\n",
       "text        56624\n",
       "location    29612\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BIO Tagging**\n",
    "\n",
    "BIO stands for Begin, Inside, and Outside. It’s a method for tagging tokens (words or subwords) in a sequence to identify entities within the text. Each token in the text is assigned a tag that indicates whether it is at the beginning of an entity, inside an entity, or outside of any entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize', verbose=False)\n",
    "\n",
    "def generate_bio_tags(text, location):\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    \n",
    "    for sentence in doc.sentences:\n",
    "        for token in sentence.tokens:\n",
    "            token_text = token.text\n",
    "            tokens.append(token_text)\n",
    "            \n",
    "            if location in token_text:\n",
    "                tags.append('B')\n",
    "                loc_words = location.split()\n",
    "                if len(loc_words) > 1:\n",
    "                    for _ in loc_words[1:]:\n",
    "                        tags.append('I')\n",
    "            else:\n",
    "                tags.append('O')\n",
    "    \n",
    "    return tokens, tags\n",
    "\n",
    "\n",
    "# Apply the function to each row in the TrainSet\n",
    "df_train['temp_tuple'] = df_train.apply(lambda row: generate_bio_tags(row['text'], row['location']), axis=1)\n",
    "df_tokens = df_train['temp_tuple'].apply(pd.Series)\n",
    "df_tokens.columns = ['tokens', 'bio_tags']\n",
    "df_train = pd.concat([df_train.drop(columns=['temp_tuple']), df_tokens], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bio_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136696589631488</td>\n",
       "      <td>Flash floods struck a Maryland city on Sunday,...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[Flash, floods, struck, a, Maryland, city, on,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001136950345109504</td>\n",
       "      <td>State of emergency declared for Maryland flood...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[State, of, emergency, declared, for, Maryland...</td>\n",
       "      <td>[O, O, O, O, O, B, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001137334056833024</td>\n",
       "      <td>Other parts of Maryland also saw significant d...</td>\n",
       "      <td>Baltimore Maryland</td>\n",
       "      <td>[Other, parts, of, Maryland, also, saw, signif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001138374923579392</td>\n",
       "      <td>Catastrophic Flooding Slams Ellicott City, Mar...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>[Catastrophic, Flooding, Slams, Ellicott, City...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_1001138377717157888</td>\n",
       "      <td>WATCH: 1 missing after flash #FLOODING devasta...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>[WATCH, :, 1, missing, after, flash, #FLOODING...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday,...   \n",
       "2  ID_1001136950345109504  State of emergency declared for Maryland flood...   \n",
       "3  ID_1001137334056833024  Other parts of Maryland also saw significant d...   \n",
       "4  ID_1001138374923579392  Catastrophic Flooding Slams Ellicott City, Mar...   \n",
       "5  ID_1001138377717157888  WATCH: 1 missing after flash #FLOODING devasta...   \n",
       "\n",
       "                 location                                             tokens  \\\n",
       "1                Maryland  [Flash, floods, struck, a, Maryland, city, on,...   \n",
       "2                Maryland  [State, of, emergency, declared, for, Maryland...   \n",
       "3      Baltimore Maryland  [Other, parts, of, Maryland, also, saw, signif...   \n",
       "4  Ellicott City Maryland  [Catastrophic, Flooding, Slams, Ellicott, City...   \n",
       "5  Ellicott City Maryland  [WATCH, :, 1, missing, after, flash, #FLOODING...   \n",
       "\n",
       "                                            bio_tags  \n",
       "1  [O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2                  [O, O, O, O, O, B, O, O, O, O, O]  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PAD Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bio_tags</th>\n",
       "      <th>tokens_padded</th>\n",
       "      <th>bio_tags_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136696589631488</td>\n",
       "      <td>Flash floods struck a Maryland city on Sunday,...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[Flash, floods, struck, a, Maryland, city, on,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[Flash, floods, struck, a, Maryland, city, on,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001136950345109504</td>\n",
       "      <td>State of emergency declared for Maryland flood...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[State, of, emergency, declared, for, Maryland...</td>\n",
       "      <td>[O, O, O, O, O, B, O, O, O, O, O]</td>\n",
       "      <td>[State, of, emergency, declared, for, Maryland...</td>\n",
       "      <td>[O, O, O, O, O, B, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001137334056833024</td>\n",
       "      <td>Other parts of Maryland also saw significant d...</td>\n",
       "      <td>Baltimore Maryland</td>\n",
       "      <td>[Other, parts, of, Maryland, also, saw, signif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[Other, parts, of, Maryland, also, saw, signif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001138374923579392</td>\n",
       "      <td>Catastrophic Flooding Slams Ellicott City, Mar...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>[Catastrophic, Flooding, Slams, Ellicott, City...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[Catastrophic, Flooding, Slams, Ellicott, City...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_1001138377717157888</td>\n",
       "      <td>WATCH: 1 missing after flash #FLOODING devasta...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>[WATCH, :, 1, missing, after, flash, #FLOODING...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[WATCH, :, 1, missing, after, flash, #FLOODING...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday,...   \n",
       "2  ID_1001136950345109504  State of emergency declared for Maryland flood...   \n",
       "3  ID_1001137334056833024  Other parts of Maryland also saw significant d...   \n",
       "4  ID_1001138374923579392  Catastrophic Flooding Slams Ellicott City, Mar...   \n",
       "5  ID_1001138377717157888  WATCH: 1 missing after flash #FLOODING devasta...   \n",
       "\n",
       "                 location                                             tokens  \\\n",
       "1                Maryland  [Flash, floods, struck, a, Maryland, city, on,...   \n",
       "2                Maryland  [State, of, emergency, declared, for, Maryland...   \n",
       "3      Baltimore Maryland  [Other, parts, of, Maryland, also, saw, signif...   \n",
       "4  Ellicott City Maryland  [Catastrophic, Flooding, Slams, Ellicott, City...   \n",
       "5  Ellicott City Maryland  [WATCH, :, 1, missing, after, flash, #FLOODING...   \n",
       "\n",
       "                                            bio_tags  \\\n",
       "1  [O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2                  [O, O, O, O, O, B, O, O, O, O, O]   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                       tokens_padded  \\\n",
       "1  [Flash, floods, struck, a, Maryland, city, on,...   \n",
       "2  [State, of, emergency, declared, for, Maryland...   \n",
       "3  [Other, parts, of, Maryland, also, saw, signif...   \n",
       "4  [Catastrophic, Flooding, Slams, Ellicott, City...   \n",
       "5  [WATCH, :, 1, missing, after, flash, #FLOODING...   \n",
       "\n",
       "                                     bio_tags_padded  \n",
       "1  [O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, B, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "5  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = df_train['tokens'].apply(len).max()\n",
    "df_train['tokens_padded'] = pad_sequences(df_train['tokens'], maxlen=max_len, dtype=object, padding='post', truncating='post', value='PAD').tolist()\n",
    "df_train['bio_tags_padded'] = pad_sequences(df_train['bio_tags'], maxlen=max_len, dtype=object, padding='post', truncating='post', value='O').tolist()\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encode Tokens and BIO Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>tokens</th>\n",
       "      <th>bio_tags</th>\n",
       "      <th>tokens_padded</th>\n",
       "      <th>bio_tags_padded</th>\n",
       "      <th>bio_tags_encoded</th>\n",
       "      <th>tokens_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136696589631488</td>\n",
       "      <td>Flash floods struck a Maryland city on Sunday,...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[Flash, floods, struck, a, Maryland, city, on,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[Flash, floods, struck, a, Maryland, city, on,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[200, 96, 463, 14, 138, 73, 27, 482, 8, 5106, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001136950345109504</td>\n",
       "      <td>State of emergency declared for Maryland flood...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>[State, of, emergency, declared, for, Maryland...</td>\n",
       "      <td>[O, O, O, O, O, B, O, O, O, O, O]</td>\n",
       "      <td>[State, of, emergency, declared, for, Maryland...</td>\n",
       "      <td>[O, O, O, O, O, B, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[107, 10, 83, 355, 12, 138, 57, 9, 106, 13, 89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001137334056833024</td>\n",
       "      <td>Other parts of Maryland also saw significant d...</td>\n",
       "      <td>Baltimore Maryland</td>\n",
       "      <td>[Other, parts, of, Maryland, also, saw, signif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[Other, parts, of, Maryland, also, saw, signif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[219, 323, 10, 138, 244, 1076, 1007, 39, 22, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001138374923579392</td>\n",
       "      <td>Catastrophic Flooding Slams Ellicott City, Mar...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>[Catastrophic, Flooding, Slams, Ellicott, City...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[Catastrophic, Flooding, Slams, Ellicott, City...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[302, 57, 1219, 310, 73, 8, 138, 167, 89, 951,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_1001138377717157888</td>\n",
       "      <td>WATCH: 1 missing after flash #FLOODING devasta...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>[WATCH, :, 1, missing, after, flash, #FLOODING...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[WATCH, :, 1, missing, after, flash, #FLOODING...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[276, 9, 159, 132, 31, 200, 6490, 1376, 310, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday,...   \n",
       "2  ID_1001136950345109504  State of emergency declared for Maryland flood...   \n",
       "3  ID_1001137334056833024  Other parts of Maryland also saw significant d...   \n",
       "4  ID_1001138374923579392  Catastrophic Flooding Slams Ellicott City, Mar...   \n",
       "5  ID_1001138377717157888  WATCH: 1 missing after flash #FLOODING devasta...   \n",
       "\n",
       "                 location                                             tokens  \\\n",
       "1                Maryland  [Flash, floods, struck, a, Maryland, city, on,...   \n",
       "2                Maryland  [State, of, emergency, declared, for, Maryland...   \n",
       "3      Baltimore Maryland  [Other, parts, of, Maryland, also, saw, signif...   \n",
       "4  Ellicott City Maryland  [Catastrophic, Flooding, Slams, Ellicott, City...   \n",
       "5  Ellicott City Maryland  [WATCH, :, 1, missing, after, flash, #FLOODING...   \n",
       "\n",
       "                                            bio_tags  \\\n",
       "1  [O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2                  [O, O, O, O, O, B, O, O, O, O, O]   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                       tokens_padded  \\\n",
       "1  [Flash, floods, struck, a, Maryland, city, on,...   \n",
       "2  [State, of, emergency, declared, for, Maryland...   \n",
       "3  [Other, parts, of, Maryland, also, saw, signif...   \n",
       "4  [Catastrophic, Flooding, Slams, Ellicott, City...   \n",
       "5  [WATCH, :, 1, missing, after, flash, #FLOODING...   \n",
       "\n",
       "                                     bio_tags_padded  \\\n",
       "1  [O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2  [O, O, O, O, O, B, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                    bio_tags_encoded  \\\n",
       "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      tokens_encoded  \n",
       "1  [200, 96, 463, 14, 138, 73, 27, 482, 8, 5106, ...  \n",
       "2  [107, 10, 83, 355, 12, 138, 57, 9, 106, 13, 89...  \n",
       "3  [219, 323, 10, 138, 244, 1076, 1007, 39, 22, 2...  \n",
       "4  [302, 57, 1219, 310, 73, 8, 138, 167, 89, 951,...  \n",
       "5  [276, 9, 159, 132, 31, 200, 6490, 1376, 310, 7...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BIO Encoding\n",
    "tag2idx = {'O': 0, 'B': 1, 'I': 2}\n",
    "df_train['bio_tags_encoded'] = df_train['bio_tags_padded'].apply(lambda x: [tag2idx[tag] for tag in x])\n",
    "\n",
    "# Token Encoding\n",
    "tokenizer = Tokenizer(oov_token='OOV')\n",
    "tokenizer.fit_on_texts(df_train['tokens_padded'])\n",
    "df_train['tokens_encoded'] = tokenizer.texts_to_sequences(df_train['tokens_padded'])\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 0.5em; background-color: #ececec; color: #000; font-weight: bold; font-size: 1.2em;\">\n",
    "    Machine learning-based NER Model for LMR\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model 1 - FeedForward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_train['tokens_encoded'].tolist())\n",
    "y = np.array(df_train['bio_tags_encoded'].tolist())\n",
    "y_one_hot = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = max_len\n",
    "NUM_CLASS   = 3\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 128 \n",
    "\n",
    "# Model\n",
    "model = models.Sequential()\n",
    "\n",
    "input_layer = Input(shape=(SIZE,))\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=SIZE)(input_layer)\n",
    "flatten_layer = Flatten()(embedding_layer)\n",
    "dense_1 = Dense(128, activation='relu')(flatten_layer)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "dense_2 = Dense(64, activation='relu')(dropout_1)\n",
    "output_layer = Dense(SIZE * 3, activation='softmax')(dense_2)\n",
    "output_layer = tf.reshape(output_layer, (-1, SIZE, 3))\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtf2crf\u001b[39;00m \u001b[39mimport\u001b[39;00m CRF\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tf2crf/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.30\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcrf\u001b[39;00m \u001b[39mimport\u001b[39;00m CRF\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel_wrapper\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tf2crf/crf.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfa\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mK\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCRF\u001b[39;00m(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLayer):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m _check_tf_version()\n\u001b[1;32m     22\u001b[0m \u001b[39m# Local project imports\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/activations/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgelu\u001b[39;00m \u001b[39mimport\u001b[39;00m gelu\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhardshrink\u001b[39;00m \u001b[39mimport\u001b[39;00m hardshrink\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlisht\u001b[39;00m \u001b[39mimport\u001b[39;00m lisht\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/activations/gelu.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorLike\n\u001b[1;32m     22\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mregister_keras_serializable(package\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAddons\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgelu\u001b[39m(x: TensorLike, approximate: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tf\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     24\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[39m    Computes gaussian error linear:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/utils/types.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m Version(tf\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mrelease \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m2.13\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mrelease:\n\u001b[1;32m     27\u001b[0m     \u001b[39m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39m# importing internal symbols.\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[1;32m     30\u001b[0m \u001b[39melif\u001b[39;00m Version(tf\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mrelease \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m2.5\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mrelease:\n\u001b[1;32m     31\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'"
     ]
    }
   ],
   "source": [
    "from tf2crf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9259407 , 0.03039424, 0.0869724 , 0.9362894 , 0.159234  ,\n",
       "         0.02058137, 0.33528695, 0.1239636 ],\n",
       "        [0.40570205, 0.36699   , 0.6836332 , 0.935297  , 0.07573988,\n",
       "         0.6030935 , 0.25253534, 0.26845726],\n",
       "        [0.26470143, 0.07290941, 0.5822046 , 0.00982825, 0.22411057,\n",
       "         0.7851651 , 0.82800126, 0.4819368 ],\n",
       "        [0.7842525 , 0.6323881 , 0.4326343 , 0.30710718, 0.15193187,\n",
       "         0.44470468, 0.4869712 , 0.34016693]],\n",
       "\n",
       "       [[0.8027908 , 0.9547014 , 0.01100268, 0.32435906, 0.40750113,\n",
       "         0.3338801 , 0.37195256, 0.1948911 ],\n",
       "        [0.702745  , 0.77574563, 0.47705722, 0.45453975, 0.34168258,\n",
       "         0.3638236 , 0.24401966, 0.46358928],\n",
       "        [0.94289315, 0.00827615, 0.11387574, 0.76900065, 0.93496716,\n",
       "         0.35411477, 0.527251  , 0.44217628],\n",
       "        [0.11547489, 0.41354004, 0.9950221 , 0.77645296, 0.18145017,\n",
       "         0.7558336 , 0.84219056, 0.3814326 ]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.rand(2, 4, 8).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.16.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m CRF\n\u001b[1;32m      5\u001b[0m \u001b[39m# Define the input layer for the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(S,), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint32)  \u001b[39m# S is the sentence length\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m _check_tf_version()\n\u001b[1;32m     22\u001b[0m \u001b[39m# Local project imports\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m \u001b[39mimport\u001b[39;00m image\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/activations/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgelu\u001b[39;00m \u001b[39mimport\u001b[39;00m gelu\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhardshrink\u001b[39;00m \u001b[39mimport\u001b[39;00m hardshrink\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlisht\u001b[39;00m \u001b[39mimport\u001b[39;00m lisht\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/activations/gelu.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_addons\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorLike\n\u001b[1;32m     22\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mregister_keras_serializable(package\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAddons\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgelu\u001b[39m(x: TensorLike, approximate: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tf\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     24\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[39m    Computes gaussian error linear:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/utils/types.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m Version(tf\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mrelease \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m2.13\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mrelease:\n\u001b[1;32m     27\u001b[0m     \u001b[39m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39m# importing internal symbols.\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[1;32m     30\u001b[0m \u001b[39melif\u001b[39;00m Version(tf\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mrelease \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m2.5\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mrelease:\n\u001b[1;32m     31\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow_addons.layers import CRF\n",
    "\n",
    "# Define the input layer for the model\n",
    "input = layers.Input(shape=(S,), dtype=tf.int32)  # S is the sentence length\n",
    "\n",
    "# Embedding layer to convert tokens into dense vectors\n",
    "embedding = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input)\n",
    "\n",
    "# Bi-LSTM layer\n",
    "bi_lstm = layers.Bidirectional(layers.LSTM(units=128, return_sequences=True))(embedding)\n",
    "\n",
    "# Dense layer before CRF\n",
    "dense = layers.TimeDistributed(layers.Dense(64, activation=\"relu\"))(bi_lstm)\n",
    "\n",
    "# CRF layer\n",
    "crf = CRF(units=num_classes)  # num_classes could be 3 (for 0, 1, 2 labels)\n",
    "output = crf(dense)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=crf.loss, metrics=[crf.accuracy])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
