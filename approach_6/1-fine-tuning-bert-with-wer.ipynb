{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90b7ba36",
   "metadata": {
    "papermill": {
     "duration": 0.010498,
     "end_time": "2024-09-04T08:56:30.760743",
     "exception": false,
     "start_time": "2024-09-04T08:56:30.750245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"padding: 0.5em; background-color: #1876d1; color: #fff; font-weight: bold; font-size: 1.4em;\">\n",
    "    Fine-Tuning BERT for Location Mention Recognition\n",
    "</div>\n",
    "\n",
    "This notebook demonstrates the process of fine-tuning a BERT model to recognize and categorize location mentions in text using the IDRISI dataset. The task at hand is a type of Named Entity Recognition (NER) where the goal is to identify and classify location names, such as countries, cities, or landmarks, within a given text.\n",
    "\n",
    "We utilize the BILOU (Begin, Inside, Last, Outside, Unit) labeling scheme, which provides detailed annotations of entity boundaries. Fine-tuning BERT with these structured labels allows the model to leverage its deep contextual understanding to perform highly accurate token classification, essential for detecting location mentions in diverse textual data.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "1. **Setup and Installation**: Install and import the necessary libraries.\n",
    "2. **Data Ingestion and Preprocessing**: Load the IDRISI dataset and prepare it for modeling, including tokenization and label mapping.\n",
    "3. **Modeling Preparation**: Create custom datasets, define label mappings, and set up the BERT model for token classification.\n",
    "4. **Fine-Tuning**: Train the BERT model on the labeled data, optimizing for accuracy in location mention recognition.\n",
    "5. **Evaluation**: Assess the performance of the fine-tuned model using the Word Error Rate Metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27f4870d",
   "metadata": {
    "papermill": {
     "duration": 0.009283,
     "end_time": "2024-09-04T08:56:30.780648",
     "exception": false,
     "start_time": "2024-09-04T08:56:30.771365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Setup & Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8af888a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:56:30.800802Z",
     "iopub.status.busy": "2024-09-04T08:56:30.800336Z",
     "iopub.status.idle": "2024-09-04T08:57:00.013949Z",
     "shell.execute_reply": "2024-09-04T08:57:00.012824Z"
    },
    "papermill": {
     "duration": 29.226751,
     "end_time": "2024-09-04T08:57:00.016507",
     "exception": false,
     "start_time": "2024-09-04T08:56:30.789756",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install transformers jiwer pandas accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99e166b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:57:00.041748Z",
     "iopub.status.busy": "2024-09-04T08:57:00.041370Z",
     "iopub.status.idle": "2024-09-04T08:57:21.767498Z",
     "shell.execute_reply": "2024-09-04T08:57:21.766664Z"
    },
    "papermill": {
     "duration": 21.741571,
     "end_time": "2024-09-04T08:57:21.770055",
     "exception": false,
     "start_time": "2024-09-04T08:57:00.028484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import sys, os, re, torch, werpy, jiwer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ml commons\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# devie septup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# utils setup\n",
    "current_directory = os.getcwd()\n",
    "root_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "sys.path.append(root_directory)\n",
    "\n",
    "# custom utils\n",
    "from utils.io import Predictions\n",
    "from utils.metrics import LMR_Metrics\n",
    "from utils.io import LMR_BILOU_Scrapper, LMR_JSON_Scrapper\n",
    "from utils.preprocessing import Preprocess\n",
    "from utils.stratify import MultiLabelNERStratify"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9853b86b",
   "metadata": {
    "papermill": {
     "duration": 0.011625,
     "end_time": "2024-09-04T08:57:21.793718",
     "exception": false,
     "start_time": "2024-09-04T08:57:21.782093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4627575f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:57:21.819138Z",
     "iopub.status.busy": "2024-09-04T08:57:21.818463Z",
     "iopub.status.idle": "2024-09-04T08:57:21.852847Z",
     "shell.execute_reply": "2024-09-04T08:57:21.851955Z"
    },
    "papermill": {
     "duration": 0.049411,
     "end_time": "2024-09-04T08:57:21.854864",
     "exception": false,
     "start_time": "2024-09-04T08:57:21.805453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def ingest_idrisi_data(bilou_base_dir='/kaggle/input/idrisi-location-mention/LMR/data/EN/gold-random-bilou/'):\n",
    "#     sentences, labels = [], []\n",
    "#     for root, dirs, files in os.walk(bilou_base_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.txt'):\n",
    "#                 file_path = os.path.join(root, file)\n",
    "#                 with open(file_path, 'r') as f:\n",
    "#                     current_sentence, current_labels = [], []\n",
    "#                     for line in f:\n",
    "#                         word_label = line.strip().split()\n",
    "#                         if len(word_label) == 2:\n",
    "#                             word, label = word_label\n",
    "#                             current_sentence.append(word)\n",
    "#                             current_labels.append(label)\n",
    "#                         elif len(current_sentence) > 0:\n",
    "#                             sentences.append(' '.join(current_sentence))\n",
    "#                             labels.append(','.join(current_labels))\n",
    "#                             current_sentence, current_labels = [], []\n",
    "#                     if len(current_sentence) > 0:\n",
    "#                         sentences.append(' '.join(current_sentence))\n",
    "#                         labels.append(','.join(current_labels))\n",
    "#     return pd.DataFrame({'sentence': sentences, 'word_labels': labels})\n",
    "\n",
    "def infer_on_sentences(sentences, model, tokenizer, max_len=300, with_extra=False):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    results = []\n",
    "    extra_results = []\n",
    "    \n",
    "    for sentence in tqdm(sentences):\n",
    "        # Tokenize the sentence and prepare input for the model\n",
    "        tokenized_sentence = tokenizer(\n",
    "            sentence.split(),\n",
    "            is_split_into_words=True,\n",
    "            return_offsets_mapping=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move tensors to the correct device\n",
    "        input_ids = tokenized_sentence['input_ids'].to(device)\n",
    "        attention_mask = tokenized_sentence['attention_mask'].to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=2)  # Get the index of the highest logit for each token\n",
    "        \n",
    "        # Convert predictions to labels\n",
    "        pred_labels = [id2label[pred.item()] for pred in predictions[0]]\n",
    "        \n",
    "        # Get the original tokens from input_ids\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        \n",
    "        # Filter out tokens with the 'O' label and concatenate them\n",
    "        filtered_tokens = [\n",
    "            token for token, label in zip(tokens, pred_labels)\n",
    "            if label != 'O' and token not in ['[CLS]', '[SEP]', '[PAD]']\n",
    "        ]\n",
    "        filtered_labels = [\n",
    "            label for token, label in zip(tokens, pred_labels)\n",
    "            if label != 'O' and token not in ['[CLS]', '[SEP]', '[PAD]']\n",
    "        ]\n",
    "        \n",
    "        results.append(\" \".join(filtered_tokens))\n",
    "        extra_results.append(filtered_labels)\n",
    "\n",
    "    if with_extra:\n",
    "        return results, extra_results\n",
    "\n",
    "    return results\n",
    "\n",
    "def calculate_performance_metric(df, col1='location', col2='prediction'):\n",
    "\n",
    "    # Function to calculate WER for each row\n",
    "    def calculate_wer(row):\n",
    "        return jiwer.wer(str(row[col1]), str(row[col2]))\n",
    "\n",
    "    # Calculate WER for each row\n",
    "    df['WER'] = df.apply(calculate_wer, axis=1)\n",
    "\n",
    "    # Calculate the average WER\n",
    "    average_wer = df['WER'].mean()\n",
    "\n",
    "    return df, average_wer\n",
    "\n",
    "def clean_text(text):\n",
    "    # Define a dictionary of replacements\n",
    "    replacements = {\n",
    "        \",\": \" \",\n",
    "        \"@\": \"\",\n",
    "        \".\": \"\",\n",
    "        \";\": \"\",\n",
    "        \"-\": \" \",\n",
    "        \"_\": \"\",\n",
    "        \"#\": \"\",\n",
    "        \"##\": \"\"\n",
    "    }\n",
    "    \n",
    "    cleaned_text = text\n",
    "    for k, v in replacements.items():\n",
    "        cleaned_text = cleaned_text.replace(k, v)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def clean_prediction(row, raw_prediction_col='prediction_raw'):\n",
    "    prediction = row[raw_prediction_col]\n",
    "    prediction = prediction.replace(\" ##\", \"\")\n",
    "    if prediction.startswith(\"##\"):\n",
    "        prediction = \" \".join(prediction.split()[1:])\n",
    "\n",
    "    cleaned_text = clean_text(row['text'])\n",
    "    lower_upper_map = {k.lower(): k for k in cleaned_text.split()}\n",
    "\n",
    "    for k, v in lower_upper_map.items():\n",
    "        prediction = prediction.replace(k, v)\n",
    "\n",
    "    replacements = {\n",
    "        \"U S .\": \"\",\n",
    "        \"L . A .\": \"L.A.\",\n",
    "        \"P R . P R .\": \"P.R.\",\n",
    "        \"N C . N C\": \"N.C.\",\n",
    "        \"u . s .\": \"U.S.\",\n",
    "        \"s . c .\": \"S.C.\",\n",
    "        \"n . c . n . c\": \"N.C.\",\n",
    "        \"n . c .\": \"N.C.\",\n",
    "        \"d . c .\": \"D.C.\",\n",
    "        \"n c . n c\": \"N.C.\",\n",
    "        '. r . p . r .': \"P.R.\",\n",
    "        \"u s .\": \"U.S.\",\n",
    "\n",
    "        \" sc\": \"\",\n",
    "        \" St\": \"\",\n",
    "        \" -\": \"\",\n",
    "        \" .\": \"\",\n",
    "        \" _\": \"\",\n",
    "    }\n",
    "    cleaned_prediction = prediction\n",
    "    for k, v in replacements.items():\n",
    "        cleaned_prediction = cleaned_prediction.replace(k, v)\n",
    "\n",
    "    prediction_words = cleaned_prediction.split()\n",
    "    if len(prediction_words) > 5:\n",
    "        cleaned_prediction = Counter(cleaned_prediction.split()).most_common(1)[0][0]\n",
    "\n",
    "    if len(set(prediction_words)) == 1:\n",
    "        cleaned_prediction = prediction_words[0] \n",
    "\n",
    "    return cleaned_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f1f1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper 1\n",
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    tokenized_sentence, labels = [], []\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\" \")):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "        labels.extend([label] * n_subwords)\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "# Helper 2\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.data.words[index]  \n",
    "        word_labels = self.data.labels[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"]\n",
    "        labels.insert(0, \"O\")\n",
    "        labels.insert(-1, \"O\")\n",
    "\n",
    "        if len(tokenized_sentence) > self.max_len:\n",
    "            tokenized_sentence = tokenized_sentence[:self.max_len]\n",
    "            labels = labels[:self.max_len]\n",
    "        else:\n",
    "            tokenized_sentence += ['[PAD]'] * (self.max_len - len(tokenized_sentence))\n",
    "            labels += [\"O\"] * (self.max_len - len(labels))\n",
    "\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(label_ids, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "# Helper 3\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    # For WER Metrics\n",
    "    true_loc, pred_loc = [], []\n",
    "    for i in range(len(labels)):\n",
    "        label_decoded = [id2label[pred] for pred in labels[i]]\n",
    "        pred_decoded  = [id2label[pred] for pred in preds[i]]\n",
    "        filtered_pred  = \" \".join([word for word in pred_decoded if word not in ['O', '[CLS]', '[SEP]', '[PAD]']])\n",
    "        filtered_label = \" \".join([word for word in label_decoded if word not in ['O', '[CLS]', '[SEP]', '[PAD]']])\n",
    "        true_loc.append(filtered_label)\n",
    "        pred_loc.append(filtered_pred)\n",
    "    wer_scores  = werpy.wers(true_loc, pred_loc)\n",
    "    average_wer = sum(wer_scores) / len(wer_scores)\n",
    "    # print(average_wer)\n",
    "    # print(true_loc)\n",
    "    # print(pred_loc)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels.flatten(), preds.flatten(), average='weighted')\n",
    "    acc = accuracy_score(labels.flatten(), preds.flatten())\n",
    "    return {\n",
    "        'accuracy'  : acc,\n",
    "        'precision' : precision,\n",
    "        'recall'    : recall,\n",
    "        'f1'        : f1,\n",
    "        'wer'       : average_wer\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a26c052",
   "metadata": {
    "papermill": {
     "duration": 0.01146,
     "end_time": "2024-09-04T08:57:21.877885",
     "exception": false,
     "start_time": "2024-09-04T08:57:21.866425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82127fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SHAPE:  (16448, 3)\n"
     ]
    }
   ],
   "source": [
    "train_dfs = []\n",
    "dev_dfs   = []\n",
    "path_dfs  = \"../data/self_scrapped/raw\"\n",
    "for filename in os.listdir(path_dfs):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(path_dfs, filename)\n",
    "        if filename.startswith(\"train\"):\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_dfs.append(df)\n",
    "        elif filename.startswith(\"dev\"):\n",
    "            df = pd.read_csv(file_path)\n",
    "            dev_dfs.append(df)\n",
    "\n",
    "df_train = pd.concat(train_dfs, ignore_index=True) if train_dfs else pd.DataFrame()\n",
    "df_dev   = pd.concat(dev_dfs, ignore_index=True) if dev_dfs else pd.DataFrame()\n",
    "\n",
    "df_train = pd.concat([df_train, df_dev])\n",
    "print(\"TRAIN SHAPE: \", df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0d3d8",
   "metadata": {},
   "source": [
    "- Use augmented df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de9ad2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/provided/TrainEncoded.csv')\n",
    "\n",
    "def parse_location_mentions(location_mentions):\n",
    "    location_dict = {}\n",
    "    if pd.notna(location_mentions):\n",
    "        parts = location_mentions.split(' * ')\n",
    "        for part in parts:\n",
    "            location, loc_type = part.split('=>')\n",
    "            location_dict[location.strip()] = loc_type.strip()\n",
    "    return location_dict\n",
    "\n",
    "location_type_dict = {}\n",
    "for location in df_train['location_mentions'].dropna():\n",
    "    location_type_dict.update(parse_location_mentions(location))\n",
    "\n",
    "def label_location(row, location_type_dict):\n",
    "    location = row['location']\n",
    "    labeled_locations = []\n",
    "    words = location.split()\n",
    "    \n",
    "    while words:\n",
    "        for i in range(len(words), 0, -1):\n",
    "            sub_location = ' '.join(words[:i]).strip()\n",
    "            if sub_location in location_type_dict:\n",
    "                labeled_locations.append(f\"{sub_location}=>{location_type_dict[sub_location]}\")\n",
    "                words = words[i:]\n",
    "                break\n",
    "        else:\n",
    "            words = words[:-1]\n",
    "    if labeled_locations:\n",
    "        return ' * '.join(labeled_locations)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['location_mentions'] = df.apply(lambda row: label_location(row, location_type_dict), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba182b5",
   "metadata": {},
   "source": [
    "- Preprocessing pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adce285b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>location_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>EllicottCity is known for its vibrant art scene.</td>\n",
       "      <td>EllicottCity</td>\n",
       "      <td>EllicottCity=&gt;CITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136696589631488</td>\n",
       "      <td>Flash floods struck a Maryland city on Sunday ...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Maryland=&gt;STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001136950345109504</td>\n",
       "      <td>State of emergency declared for Maryland flood...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Maryland=&gt;STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001137334056833024</td>\n",
       "      <td>Other parts of Maryland also saw significant d...</td>\n",
       "      <td>Baltimore Maryland</td>\n",
       "      <td>Baltimore=&gt;CITY * Maryland=&gt;STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001138374923579392</td>\n",
       "      <td>Catastrophic Flooding Slams Ellicott City Mary...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>Ellicott City=&gt;CITY * Maryland=&gt;STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID_1001138377717157888</td>\n",
       "      <td>1 missing after flash FLOODING devastates Elli...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>Ellicott City=&gt;CITY * Maryland=&gt;STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID_1001139323075416064</td>\n",
       "      <td>The scenic spots in Ellicott City Maryland are...</td>\n",
       "      <td>Ellicott City Maryland</td>\n",
       "      <td>Ellicott City=&gt;CITY * Maryland=&gt;STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID_1001140017207459840</td>\n",
       "      <td>Maryland has a variety of historical landmarks.</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Maryland=&gt;STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID_1001140276377935872</td>\n",
       "      <td>The local food markets in Maryland are a feast...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>Maryland=&gt;STATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID_1001140804503601152</td>\n",
       "      <td>Baltimore is a popular destination for both re...</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>Baltimore=&gt;CITY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0  ID_1001136212718088192   EllicottCity is known for its vibrant art scene.   \n",
       "1  ID_1001136696589631488  Flash floods struck a Maryland city on Sunday ...   \n",
       "2  ID_1001136950345109504  State of emergency declared for Maryland flood...   \n",
       "3  ID_1001137334056833024  Other parts of Maryland also saw significant d...   \n",
       "4  ID_1001138374923579392  Catastrophic Flooding Slams Ellicott City Mary...   \n",
       "5  ID_1001138377717157888  1 missing after flash FLOODING devastates Elli...   \n",
       "6  ID_1001139323075416064  The scenic spots in Ellicott City Maryland are...   \n",
       "7  ID_1001140017207459840    Maryland has a variety of historical landmarks.   \n",
       "8  ID_1001140276377935872  The local food markets in Maryland are a feast...   \n",
       "9  ID_1001140804503601152  Baltimore is a popular destination for both re...   \n",
       "\n",
       "                 location                      location_mentions  \n",
       "0            EllicottCity                     EllicottCity=>CITY  \n",
       "1                Maryland                        Maryland=>STATE  \n",
       "2                Maryland                        Maryland=>STATE  \n",
       "3      Baltimore Maryland      Baltimore=>CITY * Maryland=>STATE  \n",
       "4  Ellicott City Maryland  Ellicott City=>CITY * Maryland=>STATE  \n",
       "5  Ellicott City Maryland  Ellicott City=>CITY * Maryland=>STATE  \n",
       "6  Ellicott City Maryland  Ellicott City=>CITY * Maryland=>STATE  \n",
       "7                Maryland                        Maryland=>STATE  \n",
       "8                Maryland                        Maryland=>STATE  \n",
       "9               Baltimore                        Baltimore=>CITY  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Preprocess.remove_non_ascii(df, column_name='text')\n",
    "df = Preprocess.remove_usertag(df, column_name='text')\n",
    "df = Preprocess.reformat_hashtag(df, column_name='text')\n",
    "df = Preprocess.remove_prefix(df, df_type=\"train\", text_column='text')\n",
    "df = Preprocess.reformat_useless_char(df, column_name='text')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0eaa197",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_path = \"../data/new/train.encoded.lemma.csv\"\n",
    "if not os.path.exists(lemma_path):\n",
    "    df_ = Preprocess.remove_stop_words(df, column_name='text', new_col=\"text_transformed\", transformation=[\n",
    "        \"tokenize\", \"lemma\", \"lower\"\n",
    "    ], save_in=lemma_path)\n",
    "else:\n",
    "    df_ = pd.read_csv(lemma_path)\n",
    "\n",
    "# Subtitution\n",
    "df = df_.drop(columns=['text'])\n",
    "df = df.rename(columns={'text_transformed': 'text'})\n",
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7854ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43335, 4)\n",
      "tweet_id                0\n",
      "location                0\n",
      "location_mentions    1831\n",
      "text                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53072dd",
   "metadata": {},
   "source": [
    "- Train dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c8cdb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SHAPE:  (33984, 4)\n",
      "DEV SHAPE:  (9351, 4)\n"
     ]
    }
   ],
   "source": [
    "df_idx, ner_classes = MultiLabelNERStratify.process_location_mentions(df)\n",
    "train_idx, test_idx, train_label_freq, test_label_freq = MultiLabelNERStratify.stratify_train_test_split_multi_label(\n",
    "    df_idx.tweet_id, \n",
    "    np.vstack(df_idx.location_array_freq.values), \n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# Filter the original DataFrame based on the tweet_id column\n",
    "train_idx_list = train_idx.tolist() if hasattr(train_idx, 'tolist') else list(train_idx)\n",
    "test_idx_list = test_idx.tolist() if hasattr(test_idx, 'tolist') else list(test_idx)\n",
    "df_train = df[df['tweet_id'].isin(train_idx_list)]\n",
    "df_dev   = df[df['tweet_id'].isin(test_idx_list)]\n",
    "\n",
    "# print repartition\n",
    "print(\"TRAIN SHAPE: \", df_train.shape)\n",
    "print(\"DEV SHAPE: \", df_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba479a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>ellicottcity</td>\n",
       "      <td>U-CITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>know</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1001136212718088192</td>\n",
       "      <td>its</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sentence_id         words  labels\n",
       "0  ID_1001136212718088192  ellicottcity  U-CITY\n",
       "1  ID_1001136212718088192            be       O\n",
       "2  ID_1001136212718088192          know       O\n",
       "3  ID_1001136212718088192           for       O\n",
       "4  ID_1001136212718088192           its       O"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tag_train = Preprocess.build_bilou_encoding(df_train, text_col=\"text\", save_in=\"../data/new/train.encoded.bilou.tag.csv\")\n",
    "df_tag_dev   = Preprocess.build_bilou_encoding(df_dev, text_col=\"text\", save_in=\"../data/new/dev.encoded.bilou.tag.csv\")\n",
    "\n",
    "df_tag_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00180f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_dataset = df_tag_train.groupby('sentence_id').agg({\n",
    "    'words': lambda x: ' '.join(x),\n",
    "    'labels': lambda x: ' '.join(x)\n",
    "}).reset_index()\n",
    "train_dataset = train_dataset.drop(columns=['sentence_id'])\n",
    "train_dataset.to_csv('../data/new/kaggle/train_dataset.csv')\n",
    "\n",
    "# Dev\n",
    "test_dataset = df_tag_dev.groupby('sentence_id').agg({\n",
    "    'words': lambda x: ' '.join(x),\n",
    "    'labels': lambda x: ' '.join(x)\n",
    "}).reset_index()\n",
    "test_dataset = test_dataset.drop(columns=['sentence_id'])\n",
    "test_dataset.to_csv('../data/new/kaggle/dev_dataset.csv')\n",
    "\n",
    "# Full\n",
    "data = pd.concat([train_dataset, test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp for debug -- should be deleted for prod training\n",
    "# test_dataset = test_dataset.sample(frac=0.001, random_state=200).reset_index(drop=True)\n",
    "# train_dataset = train_dataset.sample(frac=0.001, random_state=200).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d782a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flash flood strike a maryland city on sunday w...</td>\n",
       "      <td>O O O O U-STATE O O O O O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state of emergency declare for maryland floodi...</td>\n",
       "      <td>O O O O O U-STATE O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maryland have a variety of historical landmark</td>\n",
       "      <td>U-STATE O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the local food market in maryland be a feast f...</td>\n",
       "      <td>O O O O O U-STATE O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maryland be know for its beautiful park and ga...</td>\n",
       "      <td>U-STATE O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>mexico be know for its picturesque riverfront</td>\n",
       "      <td>U-COUNTRY O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>cuban doctor treat mexicos earthquake victim</td>\n",
       "      <td>O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>mexico be know for its picturesque landscape</td>\n",
       "      <td>U-COUNTRY O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9348</th>\n",
       "      <td>mexico earthquake relief font bundle</td>\n",
       "      <td>U-COUNTRY O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9349</th>\n",
       "      <td>donate from facebook to mexico earthquake reli...</td>\n",
       "      <td>O O O O U-COUNTRY O O O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  words  \\\n",
       "0     flash flood strike a maryland city on sunday w...   \n",
       "1     state of emergency declare for maryland floodi...   \n",
       "2        maryland have a variety of historical landmark   \n",
       "3     the local food market in maryland be a feast f...   \n",
       "4     maryland be know for its beautiful park and ga...   \n",
       "...                                                 ...   \n",
       "9345      mexico be know for its picturesque riverfront   \n",
       "9346       cuban doctor treat mexicos earthquake victim   \n",
       "9347       mexico be know for its picturesque landscape   \n",
       "9348               mexico earthquake relief font bundle   \n",
       "9349  donate from facebook to mexico earthquake reli...   \n",
       "\n",
       "                                       labels  \n",
       "0     O O O O U-STATE O O O O O O O O O O O O  \n",
       "1                       O O O O O U-STATE O O  \n",
       "2                         U-STATE O O O O O O  \n",
       "3               O O O O O U-STATE O O O O O O  \n",
       "4                     U-STATE O O O O O O O O  \n",
       "...                                       ...  \n",
       "9345                    U-COUNTRY O O O O O O  \n",
       "9346                              O O O O O O  \n",
       "9347                    U-COUNTRY O O O O O O  \n",
       "9348                        U-COUNTRY O O O O  \n",
       "9349                  O O O O U-COUNTRY O O O  \n",
       "\n",
       "[9350 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2283f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ellicottcity be know for its vibrant art scene</td>\n",
       "      <td>U-CITY O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other part of maryland also see significant da...</td>\n",
       "      <td>O O O U-STATE O O O O O O O O O U-CITY O O O O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>catastrophic flooding slam ellicott city maryl...</td>\n",
       "      <td>O O O B-CITY L-CITY U-STATE O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 miss after flash flooding devastate ellicott...</td>\n",
       "      <td>O O O O O O B-CITY L-CITY U-STATE O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the scenic spot in ellicott city maryland be p...</td>\n",
       "      <td>O O O O B-CITY L-CITY U-STATE O O O O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  \\\n",
       "0     ellicottcity be know for its vibrant art scene   \n",
       "1  other part of maryland also see significant da...   \n",
       "2  catastrophic flooding slam ellicott city maryl...   \n",
       "3  1 miss after flash flooding devastate ellicott...   \n",
       "4  the scenic spot in ellicott city maryland be p...   \n",
       "\n",
       "                                              labels  \n",
       "0                               U-CITY O O O O O O O  \n",
       "1  O O O U-STATE O O O O O O O O O U-CITY O O O O...  \n",
       "2          O O O B-CITY L-CITY U-STATE O O O O O O O  \n",
       "3                O O O O O O B-CITY L-CITY U-STATE O  \n",
       "4              O O O O B-CITY L-CITY U-STATE O O O O  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c0ecfb5",
   "metadata": {
    "papermill": {
     "duration": 0.011489,
     "end_time": "2024-09-04T08:57:22.777804",
     "exception": false,
     "start_time": "2024-09-04T08:57:22.766315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Modeling preparation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "566c1714",
   "metadata": {
    "papermill": {
     "duration": 0.011463,
     "end_time": "2024-09-04T08:57:22.800976",
     "exception": false,
     "start_time": "2024-09-04T08:57:22.789513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- **Prepare custom label mappings**: \n",
    "\n",
    "<div style=\"padding-left: 2.5em;\">Before fine-tuning, it’s essential to map the location mention labels from the BILOU format to a format that BERT can understand. This involves converting categorical labels (e.g., `B-CITY`,`B-COUNTY`, ...) into integer IDs, which the model will use during training. This mapping is critical because BERT outputs logits for each token, which are then converted back to these labels.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c591ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:57:22.849878Z",
     "iopub.status.busy": "2024-09-04T08:57:22.848990Z",
     "iopub.status.idle": "2024-09-04T08:57:22.875192Z",
     "shell.execute_reply": "2024-09-04T08:57:22.874177Z"
    },
    "papermill": {
     "duration": 0.041435,
     "end_time": "2024-09-04T08:57:22.877274",
     "exception": false,
     "start_time": "2024-09-04T08:57:22.835839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract unique tags from word labels\n",
    "tags = set(\" \".join(data.labels).split(' '))\n",
    "\n",
    "# Create label to ID and ID to label mappings\n",
    "label2id = {k: v for v, k in enumerate(tags)}\n",
    "id2label = {v: k for v, k in enumerate(tags)}\n",
    "\n",
    "# Get a look of tags\n",
    "#tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "184a8d88",
   "metadata": {
    "papermill": {
     "duration": 0.012279,
     "end_time": "2024-09-04T08:57:22.901876",
     "exception": false,
     "start_time": "2024-09-04T08:57:22.889597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Setup the model and tokenizer**\n",
    "\n",
    "- **Pretrained model for huggingface**: \n",
    "\n",
    "<div style=\"padding-left: 2.5em;\">We retrieve the tokenizer and the model from Huggingface's library of pre-trained models. This allows us to leverage a model that has already been fine-tuned for a specific task, such as Named Entity Recognition (NER). The tokenizer helps preprocess the input text by converting it into a format that the model can interpret, while the model is used to make predictions based on this input.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146bbc6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:57:22.928003Z",
     "iopub.status.busy": "2024-09-04T08:57:22.927641Z",
     "iopub.status.idle": "2024-09-04T08:58:00.307077Z",
     "shell.execute_reply": "2024-09-04T08:58:00.306056Z"
    },
    "papermill": {
     "duration": 37.394929,
     "end_time": "2024-09-04T08:58:00.309376",
     "exception": false,
     "start_time": "2024-09-04T08:57:22.914447",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-large-uncased\",\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be22bd38",
   "metadata": {
    "papermill": {
     "duration": 0.012863,
     "end_time": "2024-09-04T08:58:00.335552",
     "exception": false,
     "start_time": "2024-09-04T08:58:00.322689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- **DataCollator**: \n",
    "\n",
    "<div style=\"padding-left: 2.5em;\">\n",
    "A custom dataset class is created to handle the input data, applying tokenization and ensuring that sequences are properly padded or truncated to fit the model’s expected input size. The `DataCollatorForTokenClassification` from the Hugging Face `transformers` library is used to dynamically pad batches during training, making the process efficient and preventing data leakage between samples.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f386ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:58:00.364026Z",
     "iopub.status.busy": "2024-09-04T08:58:00.363342Z",
     "iopub.status.idle": "2024-09-04T08:58:00.367676Z",
     "shell.execute_reply": "2024-09-04T08:58:00.366780Z"
    },
    "papermill": {
     "duration": 0.020763,
     "end_time": "2024-09-04T08:58:00.369561",
     "exception": false,
     "start_time": "2024-09-04T08:58:00.348798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8627d594",
   "metadata": {},
   "source": [
    "- Create custom datasets for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f503f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].apply(lambda x: len(x.split(\" \"))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a36e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:58:00.398238Z",
     "iopub.status.busy": "2024-09-04T08:58:00.397346Z",
     "iopub.status.idle": "2024-09-04T08:58:00.402263Z",
     "shell.execute_reply": "2024-09-04T08:58:00.401429Z"
    },
    "papermill": {
     "duration": 0.021484,
     "end_time": "2024-09-04T08:58:00.404285",
     "exception": false,
     "start_time": "2024-09-04T08:58:00.382801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290a676",
   "metadata": {},
   "source": [
    "- Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e48c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:58:00.431710Z",
     "iopub.status.busy": "2024-09-04T08:58:00.431381Z",
     "iopub.status.idle": "2024-09-04T08:58:00.435441Z",
     "shell.execute_reply": "2024-09-04T08:58:00.434546Z"
    },
    "papermill": {
     "duration": 0.019737,
     "end_time": "2024-09-04T08:58:00.437322",
     "exception": false,
     "start_time": "2024-09-04T08:58:00.417585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6452d69e",
   "metadata": {
    "papermill": {
     "duration": 0.01281,
     "end_time": "2024-09-04T08:58:00.463827",
     "exception": false,
     "start_time": "2024-09-04T08:58:00.451017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Setup trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f6315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:58:00.490365Z",
     "iopub.status.busy": "2024-09-04T08:58:00.490059Z",
     "iopub.status.idle": "2024-09-04T08:58:00.538290Z",
     "shell.execute_reply": "2024-09-04T08:58:00.537340Z"
    },
    "papermill": {
     "duration": 0.064057,
     "end_time": "2024-09-04T08:58:00.540534",
     "exception": false,
     "start_time": "2024-09-04T08:58:00.476477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    warmup_steps=25,\n",
    "    weight_decay=0.001,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=25,\n",
    "    save_steps=50,\n",
    "    save_total_limit=2,\n",
    "    gradient_accumulation_steps=4,  # Accumulate gradients for larger effective batch size\n",
    "    fp16=False,  # Enable mixed precision training for faster computation\n",
    "    report_to=[\"none\"] #set this to true if you have a WANDB API key\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=testing_set,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5ee4287",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.0128,
     "end_time": "2024-09-04T08:58:00.566556",
     "exception": false,
     "start_time": "2024-09-04T08:58:00.553756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Fine-tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c8147de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:58:00.619790Z",
     "iopub.status.busy": "2024-09-04T08:58:00.619470Z",
     "iopub.status.idle": "2024-09-04T13:20:36.601242Z",
     "shell.execute_reply": "2024-09-04T13:20:36.600107Z"
    },
    "papermill": {
     "duration": 15756.054027,
     "end_time": "2024-09-04T13:20:36.659148",
     "exception": false,
     "start_time": "2024-09-04T08:58:00.605121",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e113ba18dc040d7a2e66ef93b0b35dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1939\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   1940\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1941\u001b[0m         trial\u001b[39m=\u001b[39mtrial,\n\u001b[1;32m   1942\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1943\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3320\u001b[0m \u001b[39mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtorch_empty_cache_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtorch_empty_cache_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[1;32m   3364\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1889\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1885\u001b[0m \u001b[39m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1886\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1887\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1889\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert(\n\u001b[1;32m   1890\u001b[0m     input_ids,\n\u001b[1;32m   1891\u001b[0m     attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m   1892\u001b[0m     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1893\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   1894\u001b[0m     head_mask\u001b[39m=\u001b[39mhead_mask,\n\u001b[1;32m   1895\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[1;32m   1896\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m   1897\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1898\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1899\u001b[0m )\n\u001b[1;32m   1901\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1903\u001b[0m sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1141\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1142\u001b[0m     embedding_output,\n\u001b[1;32m   1143\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   1144\u001b[0m     head_mask\u001b[39m=\u001b[39mhead_mask,\n\u001b[1;32m   1145\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1146\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m   1147\u001b[0m     past_key_values\u001b[39m=\u001b[39mpast_key_values,\n\u001b[1;32m   1148\u001b[0m     use_cache\u001b[39m=\u001b[39muse_cache,\n\u001b[1;32m   1149\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m   1150\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1151\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1152\u001b[0m )\n\u001b[1;32m   1153\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    684\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    685\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m         output_attentions,\n\u001b[1;32m    692\u001b[0m     )\n\u001b[1;32m    693\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    695\u001b[0m         hidden_states,\n\u001b[1;32m    696\u001b[0m         attention_mask,\n\u001b[1;32m    697\u001b[0m         layer_head_mask,\n\u001b[1;32m    698\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    699\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    700\u001b[0m         past_key_value,\n\u001b[1;32m    701\u001b[0m         output_attentions,\n\u001b[1;32m    702\u001b[0m     )\n\u001b[1;32m    704\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    705\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:584\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    573\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    574\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    582\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(\n\u001b[1;32m    585\u001b[0m         hidden_states,\n\u001b[1;32m    586\u001b[0m         attention_mask,\n\u001b[1;32m    587\u001b[0m         head_mask,\n\u001b[1;32m    588\u001b[0m         output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m    589\u001b[0m         past_key_value\u001b[39m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    590\u001b[0m     )\n\u001b[1;32m    591\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    505\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    506\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 514\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself(\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[1;32m    516\u001b[0m         attention_mask,\n\u001b[1;32m    517\u001b[0m         head_mask,\n\u001b[1;32m    518\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    519\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    520\u001b[0m         past_key_value,\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    524\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m is_causal \u001b[39m=\u001b[39m (\n\u001b[1;32m    436\u001b[0m     \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cross_attention \u001b[39mand\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m tgt_len \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    437\u001b[0m )\n\u001b[0;32m--> 439\u001b[0m attn_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mscaled_dot_product_attention(\n\u001b[1;32m    440\u001b[0m     query_layer,\n\u001b[1;32m    441\u001b[0m     key_layer,\n\u001b[1;32m    442\u001b[0m     value_layer,\n\u001b[1;32m    443\u001b[0m     attn_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m    444\u001b[0m     dropout_p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_prob \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39melse\u001b[39;00m \u001b[39m0.0\u001b[39m,\n\u001b[1;32m    445\u001b[0m     is_causal\u001b[39m=\u001b[39mis_causal,\n\u001b[1;32m    446\u001b[0m )\n\u001b[1;32m    448\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    449\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mreshape(bsz, tgt_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_head_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0d2e5f",
   "metadata": {
    "papermill": {
     "duration": 0.033349,
     "end_time": "2024-09-04T13:20:36.726154",
     "exception": false,
     "start_time": "2024-09-04T13:20:36.692805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Measuring average WER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38135d6",
   "metadata": {
    "papermill": {
     "duration": 0.033,
     "end_time": "2024-09-04T13:20:36.792579",
     "exception": false,
     "start_time": "2024-09-04T13:20:36.759579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that the model is trained, let's make inference on train data to evaluate against the custom metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b1d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:20:36.840817Z",
     "iopub.status.busy": "2024-09-04T13:20:36.840386Z",
     "iopub.status.idle": "2024-09-04T13:20:37.065609Z",
     "shell.execute_reply": "2024-09-04T13:20:37.064443Z"
    },
    "papermill": {
     "duration": 0.246159,
     "end_time": "2024-09-04T13:20:37.068256",
     "exception": false,
     "start_time": "2024-09-04T13:20:36.822097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"/kaggle/input/dattttt/dat/Train.csv\")\n",
    "# \n",
    "# train = train[~train['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9744b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:20:37.120073Z",
     "iopub.status.busy": "2024-09-04T13:20:37.118004Z",
     "iopub.status.idle": "2024-09-04T13:36:00.990157Z",
     "shell.execute_reply": "2024-09-04T13:36:00.989098Z"
    },
    "papermill": {
     "duration": 923.897729,
     "end_time": "2024-09-04T13:36:00.992298",
     "exception": false,
     "start_time": "2024-09-04T13:20:37.094569",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16448/16448 [15:23<00:00, 17.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# implement in batches later\n",
    "# train_predictions = infer_on_sentences(train.text.to_list(), trainer.model, tokenizer)\n",
    "# train['prediction_raw'] = train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644a266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:36:02.358683Z",
     "iopub.status.busy": "2024-09-04T13:36:02.358296Z",
     "iopub.status.idle": "2024-09-04T13:36:02.509249Z",
     "shell.execute_reply": "2024-09-04T13:36:02.508449Z"
    },
    "papermill": {
     "duration": 0.860531,
     "end_time": "2024-09-04T13:36:02.511433",
     "exception": false,
     "start_time": "2024-09-04T13:36:01.650902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.to_csv('news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6506ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:36:03.823427Z",
     "iopub.status.busy": "2024-09-04T13:36:03.822574Z",
     "iopub.status.idle": "2024-09-04T13:36:04.812855Z",
     "shell.execute_reply": "2024-09-04T13:36:04.811947Z"
    },
    "papermill": {
     "duration": 1.652997,
     "end_time": "2024-09-04T13:36:04.814832",
     "exception": false,
     "start_time": "2024-09-04T13:36:03.161835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.28802675855813"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df, average_wer = calculate_performance_metric(train, col2='prediction_raw')\n",
    "# average_wer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff61eb",
   "metadata": {
    "papermill": {
     "duration": 0.653784,
     "end_time": "2024-09-04T13:36:06.168518",
     "exception": false,
     "start_time": "2024-09-04T13:36:05.514734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Can we do better?\n",
    "\n",
    "Here we will perform some post-inference cleaning,using the `clean_prediction` function defined in the helpers section. Nothing fancy, just a bunch of heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf82e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:36:07.547623Z",
     "iopub.status.busy": "2024-09-04T13:36:07.547246Z",
     "iopub.status.idle": "2024-09-04T13:36:08.131536Z",
     "shell.execute_reply": "2024-09-04T13:36:08.130733Z"
    },
    "papermill": {
     "duration": 1.263966,
     "end_time": "2024-09-04T13:36:08.133806",
     "exception": false,
     "start_time": "2024-09-04T13:36:06.869840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train['prediction_clean'] = train.apply(clean_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336a21f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:36:09.493951Z",
     "iopub.status.busy": "2024-09-04T13:36:09.493081Z",
     "iopub.status.idle": "2024-09-04T13:36:10.412572Z",
     "shell.execute_reply": "2024-09-04T13:36:10.411604Z"
    },
    "papermill": {
     "duration": 1.618946,
     "end_time": "2024-09-04T13:36:10.414782",
     "exception": false,
     "start_time": "2024-09-04T13:36:08.795836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019827050651466"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df, average_wer = calculate_performance_metric(train, col2='prediction_clean')\n",
    "# average_wer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e282bb",
   "metadata": {
    "papermill": {
     "duration": 0.65538,
     "end_time": "2024-09-04T13:36:11.752234",
     "exception": false,
     "start_time": "2024-09-04T13:36:11.096854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3fbe7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:36:13.116763Z",
     "iopub.status.busy": "2024-09-04T13:36:13.115991Z",
     "iopub.status.idle": "2024-09-04T13:36:13.153209Z",
     "shell.execute_reply": "2024-09-04T13:36:13.151967Z"
    },
    "papermill": {
     "duration": 0.69807,
     "end_time": "2024-09-04T13:36:13.155300",
     "exception": false,
     "start_time": "2024-09-04T13:36:12.457230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv(\"/kaggle/input/dattttt/dat/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee77ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:36:14.502907Z",
     "iopub.status.busy": "2024-09-04T13:36:14.502518Z",
     "iopub.status.idle": "2024-09-04T13:38:59.702564Z",
     "shell.execute_reply": "2024-09-04T13:38:59.701453Z"
    },
    "papermill": {
     "duration": 165.902593,
     "end_time": "2024-09-04T13:38:59.705065",
     "exception": false,
     "start_time": "2024-09-04T13:36:13.802472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2942/2942 [02:45<00:00, 17.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# implement in batches later\n",
    "# test_predictions = infer_on_sentences(test.text.to_list(), model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515719f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:39:01.291035Z",
     "iopub.status.busy": "2024-09-04T13:39:01.289822Z",
     "iopub.status.idle": "2024-09-04T13:39:01.403608Z",
     "shell.execute_reply": "2024-09-04T13:39:01.402816Z"
    },
    "papermill": {
     "duration": 0.931178,
     "end_time": "2024-09-04T13:39:01.405725",
     "exception": false,
     "start_time": "2024-09-04T13:39:00.474547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test['prediction_raw'] = test_predictions\n",
    "# test['prediction'] = test.apply(clean_prediction, axis=1)\n",
    "# test['prediction'] = test['prediction'].replace(\"\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26231f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T13:39:02.961877Z",
     "iopub.status.busy": "2024-09-04T13:39:02.961111Z",
     "iopub.status.idle": "2024-09-04T13:39:02.977120Z",
     "shell.execute_reply": "2024-09-04T13:39:02.976283Z"
    },
    "papermill": {
     "duration": 0.786355,
     "end_time": "2024-09-04T13:39:02.978937",
     "exception": false,
     "start_time": "2024-09-04T13:39:02.192582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test[['tweet_id', 'prediction']].to_csv(\"bert-large-uncased-fine-tuned-1-epoch+huristic-cleaning.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5561463,
     "sourceId": 9198868,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5642016,
     "sourceId": 9315341,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16963.297039,
   "end_time": "2024-09-04T13:39:11.404959",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-04T08:56:28.107920",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "12cc95c67db2413a956b439054d379ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14396cd2b60243df89e5c9facdd9e4b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "18adc4f601fd453aab7f0db3c6006c22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e9ab3140676e428a82efe168fe8a2c56",
       "placeholder": "​",
       "style": "IPY_MODEL_261a0da9fe2e4ed28c3dfc6d587ed707",
       "value": " 232k/232k [00:00&lt;00:00, 12.3MB/s]"
      }
     },
     "19de9c83f4274d19a4da2158615a6c82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1af0a1ac3d3d4b33bdc55be45a1ebd54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f747e9ecd0344e7b31ee61d0e013e2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22177923f3284cdd8b5fd7864f8258a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1f747e9ecd0344e7b31ee61d0e013e2d",
       "placeholder": "​",
       "style": "IPY_MODEL_849506128eaf43a6b33936a2a651c240",
       "value": "config.json: 100%"
      }
     },
     "261a0da9fe2e4ed28c3dfc6d587ed707": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "28e0fb070bcd49bf809fab70702d2efe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28fa81b43ce049738faa8a873cadadaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "347d85815bde46fe94878d1d02ce8d15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_22177923f3284cdd8b5fd7864f8258a7",
        "IPY_MODEL_9d6213a5b659455c911bc26cec180359",
        "IPY_MODEL_cadbe681538e40f8bb5625e263c44673"
       ],
       "layout": "IPY_MODEL_9c366a43cbc8495b82689329926e9b83"
      }
     },
     "3f1e6db6b1b74cd0b1821102f99177d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3f86be6bf412444287789978cc24a738",
       "placeholder": "​",
       "style": "IPY_MODEL_5a5dfa968ce247799c7ad4abf9254a0d",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "3f86be6bf412444287789978cc24a738": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c555d7d69f64a07ad910f8acbde9de5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "521b75650510473898b7cf8f93365fc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "555f31427c3142d0b1f634246a0f88e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a5dfa968ce247799c7ad4abf9254a0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5c8aead566204d45af94989fa235d774": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5cb0cb8fd5014ecc9713df2f88ee7e95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5c8aead566204d45af94989fa235d774",
       "placeholder": "​",
       "style": "IPY_MODEL_28fa81b43ce049738faa8a873cadadaa",
       "value": " 1.34G/1.34G [00:33&lt;00:00, 42.4MB/s]"
      }
     },
     "635bc918049d4ddcbe61088ba9d4ba76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "65f0db0d0ef24ab1a29e46e8b2fb7dd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_943f317332ae4fe4abddfc8e8d7a6e7d",
       "placeholder": "​",
       "style": "IPY_MODEL_c008b5ade97947eba854bbee21696f8e",
       "value": "model.safetensors: 100%"
      }
     },
     "6b10ba0946474c1c8899ce2628432319": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1af0a1ac3d3d4b33bdc55be45a1ebd54",
       "placeholder": "​",
       "style": "IPY_MODEL_14396cd2b60243df89e5c9facdd9e4b0",
       "value": "tokenizer.json: 100%"
      }
     },
     "79ee4b3c84c24fdcb2fbb0ea45d05750": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7af8e709fb994237befe3a8731df307d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b6df7377ac34d2b969f7bb0d7e6e2ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7af8e709fb994237befe3a8731df307d",
       "placeholder": "​",
       "style": "IPY_MODEL_ddffd235e8b249c186457a29c12e9ac0",
       "value": " 466k/466k [00:00&lt;00:00, 33.0MB/s]"
      }
     },
     "849506128eaf43a6b33936a2a651c240": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8848f31b0af74783aa7afc2b5beecd10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "943f317332ae4fe4abddfc8e8d7a6e7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "971189af43ff4f46886a7d06475b6de3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "99f6a2b83cb9409597ca100d74e2b5ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bccbfcc1dc714501aa3e7ed22c57c209",
       "placeholder": "​",
       "style": "IPY_MODEL_f2afb732ce244d35b6e0ae49c09672a0",
       "value": "vocab.txt: 100%"
      }
     },
     "9c366a43cbc8495b82689329926e9b83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d6213a5b659455c911bc26cec180359": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_79ee4b3c84c24fdcb2fbb0ea45d05750",
       "max": 571,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c48fa5f405794c489cff23b639bd2ec5",
       "value": 571
      }
     },
     "a68a32d23e4b4018ab412aed928eafd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_65f0db0d0ef24ab1a29e46e8b2fb7dd2",
        "IPY_MODEL_b418e57c31a24583a3e9d8ffee66da44",
        "IPY_MODEL_5cb0cb8fd5014ecc9713df2f88ee7e95"
       ],
       "layout": "IPY_MODEL_cd43f894455b431f81325f2662de0888"
      }
     },
     "ab66683095f44d5b82e4ce40d13c4f8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_28e0fb070bcd49bf809fab70702d2efe",
       "placeholder": "​",
       "style": "IPY_MODEL_f7406591d7354fa8b9390a5d57d2e443",
       "value": " 48.0/48.0 [00:00&lt;00:00, 4.09kB/s]"
      }
     },
     "ae66ba0cf4764a75aa07e6acecf1615a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8848f31b0af74783aa7afc2b5beecd10",
       "max": 466062,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5285f044d8e418e807c468bbed7e544",
       "value": 466062
      }
     },
     "b418e57c31a24583a3e9d8ffee66da44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_19de9c83f4274d19a4da2158615a6c82",
       "max": 1344951957,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_971189af43ff4f46886a7d06475b6de3",
       "value": 1344951957
      }
     },
     "b5f638a0e89c4d8da6bee55dd2fc4d29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b939716fd1e74fc1a81aca75d27a52ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bba2448523154af083824efe43d32eb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b10ba0946474c1c8899ce2628432319",
        "IPY_MODEL_ae66ba0cf4764a75aa07e6acecf1615a",
        "IPY_MODEL_7b6df7377ac34d2b969f7bb0d7e6e2ab"
       ],
       "layout": "IPY_MODEL_bf00cf2648a547d49b0239531776db57"
      }
     },
     "bccbfcc1dc714501aa3e7ed22c57c209": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf00cf2648a547d49b0239531776db57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c008b5ade97947eba854bbee21696f8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c48fa5f405794c489cff23b639bd2ec5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cadbe681538e40f8bb5625e263c44673": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c555d7d69f64a07ad910f8acbde9de5",
       "placeholder": "​",
       "style": "IPY_MODEL_521b75650510473898b7cf8f93365fc3",
       "value": " 571/571 [00:00&lt;00:00, 44.3kB/s]"
      }
     },
     "cbba1e13544f4ab097e9b7c4ed93d174": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e19643b5e12b456aaf7db1c682338c6d",
       "max": 48,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_635bc918049d4ddcbe61088ba9d4ba76",
       "value": 48
      }
     },
     "cd43f894455b431f81325f2662de0888": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d7f2f867f0004129890fc40121495075": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3f1e6db6b1b74cd0b1821102f99177d4",
        "IPY_MODEL_cbba1e13544f4ab097e9b7c4ed93d174",
        "IPY_MODEL_ab66683095f44d5b82e4ce40d13c4f8f"
       ],
       "layout": "IPY_MODEL_12cc95c67db2413a956b439054d379ba"
      }
     },
     "ddffd235e8b249c186457a29c12e9ac0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e0c8064285d74c0e8e2986e5294a92c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_99f6a2b83cb9409597ca100d74e2b5ff",
        "IPY_MODEL_e2ae0981bbab41e3a4daa19bad392a25",
        "IPY_MODEL_18adc4f601fd453aab7f0db3c6006c22"
       ],
       "layout": "IPY_MODEL_b939716fd1e74fc1a81aca75d27a52ee"
      }
     },
     "e19643b5e12b456aaf7db1c682338c6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2ae0981bbab41e3a4daa19bad392a25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_555f31427c3142d0b1f634246a0f88e1",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b5f638a0e89c4d8da6bee55dd2fc4d29",
       "value": 231508
      }
     },
     "e9ab3140676e428a82efe168fe8a2c56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2afb732ce244d35b6e0ae49c09672a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f5285f044d8e418e807c468bbed7e544": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f7406591d7354fa8b9390a5d57d2e443": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
